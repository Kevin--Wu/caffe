I1107 15:06:02.457067  3455 caffe.cpp:217] Using GPUs 0
I1107 15:06:02.552464  3455 caffe.cpp:222] GPU 0: Tesla K40c
I1107 15:06:02.676740  3455 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 500
base_lr: 0.0001
display: 500
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 10000
snapshot_prefix: "mywork/hmdb51/snapshot/hmdb_vgg2048"
solver_mode: GPU
device_id: 0
net: "mywork/hmdb51/vgg_m_2048_net.prototxt"
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I1107 15:06:02.676831  3455 solver.cpp:91] Creating training net from net file: mywork/hmdb51/vgg_m_2048_net.prototxt
I1107 15:06:02.690641  3455 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer test_data
I1107 15:06:02.690657  3455 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1107 15:06:02.690778  3455 net.cpp:58] Initializing net from parameters: 
name: "VGG_CNN_M_2048"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "train_data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/hadoop/whx/dataset/hmdb/jpg_output/hmdb51_train_lmdb/split1"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 5
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_hmdb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 100
  }
  param {
    lr_mult: 100
  }
  inner_product_param {
    num_output: 51
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1107 15:06:02.690855  3455 layer_factory.hpp:77] Creating layer train_data
I1107 15:06:02.691217  3455 net.cpp:100] Creating Layer train_data
I1107 15:06:02.691226  3455 net.cpp:408] train_data -> data
I1107 15:06:02.691243  3455 net.cpp:408] train_data -> label
I1107 15:06:02.691769  3466 db_lmdb.cpp:35] Opened lmdb /home/hadoop/whx/dataset/hmdb/jpg_output/hmdb51_train_lmdb/split1
I1107 15:06:02.697697  3455 data_layer.cpp:41] output data size: 64,3,224,224
I1107 15:06:02.736455  3455 net.cpp:150] Setting up train_data
I1107 15:06:02.736484  3455 net.cpp:157] Top shape: 64 3 224 224 (9633792)
I1107 15:06:02.736487  3455 net.cpp:157] Top shape: 64 (64)
I1107 15:06:02.736491  3455 net.cpp:165] Memory required for data: 38535424
I1107 15:06:02.736497  3455 layer_factory.hpp:77] Creating layer conv1
I1107 15:06:02.736511  3455 net.cpp:100] Creating Layer conv1
I1107 15:06:02.736515  3455 net.cpp:434] conv1 <- data
I1107 15:06:02.736523  3455 net.cpp:408] conv1 -> conv1
I1107 15:06:02.859102  3455 net.cpp:150] Setting up conv1
I1107 15:06:02.859128  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:02.859133  3455 net.cpp:165] Memory required for data: 330522880
I1107 15:06:02.859144  3455 layer_factory.hpp:77] Creating layer relu1
I1107 15:06:02.859154  3455 net.cpp:100] Creating Layer relu1
I1107 15:06:02.859158  3455 net.cpp:434] relu1 <- conv1
I1107 15:06:02.859163  3455 net.cpp:395] relu1 -> conv1 (in-place)
I1107 15:06:02.859326  3455 net.cpp:150] Setting up relu1
I1107 15:06:02.859335  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:02.859338  3455 net.cpp:165] Memory required for data: 622510336
I1107 15:06:02.859341  3455 layer_factory.hpp:77] Creating layer norm1
I1107 15:06:02.859349  3455 net.cpp:100] Creating Layer norm1
I1107 15:06:02.859351  3455 net.cpp:434] norm1 <- conv1
I1107 15:06:02.859355  3455 net.cpp:408] norm1 -> norm1
I1107 15:06:02.859534  3455 net.cpp:150] Setting up norm1
I1107 15:06:02.859542  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:02.859545  3455 net.cpp:165] Memory required for data: 914497792
I1107 15:06:02.859547  3455 layer_factory.hpp:77] Creating layer pool1
I1107 15:06:02.859553  3455 net.cpp:100] Creating Layer pool1
I1107 15:06:02.859556  3455 net.cpp:434] pool1 <- norm1
I1107 15:06:02.859560  3455 net.cpp:408] pool1 -> pool1
I1107 15:06:02.859586  3455 net.cpp:150] Setting up pool1
I1107 15:06:02.859591  3455 net.cpp:157] Top shape: 64 96 54 54 (17915904)
I1107 15:06:02.859593  3455 net.cpp:165] Memory required for data: 986161408
I1107 15:06:02.859596  3455 layer_factory.hpp:77] Creating layer conv2
I1107 15:06:02.859603  3455 net.cpp:100] Creating Layer conv2
I1107 15:06:02.859606  3455 net.cpp:434] conv2 <- pool1
I1107 15:06:02.859609  3455 net.cpp:408] conv2 -> conv2
I1107 15:06:02.861001  3455 net.cpp:150] Setting up conv2
I1107 15:06:02.861011  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:02.861014  3455 net.cpp:165] Memory required for data: 1030463744
I1107 15:06:02.861021  3455 layer_factory.hpp:77] Creating layer relu2
I1107 15:06:02.861027  3455 net.cpp:100] Creating Layer relu2
I1107 15:06:02.861029  3455 net.cpp:434] relu2 <- conv2
I1107 15:06:02.861032  3455 net.cpp:395] relu2 -> conv2 (in-place)
I1107 15:06:02.861203  3455 net.cpp:150] Setting up relu2
I1107 15:06:02.861212  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:02.861214  3455 net.cpp:165] Memory required for data: 1074766080
I1107 15:06:02.861217  3455 layer_factory.hpp:77] Creating layer norm2
I1107 15:06:02.861222  3455 net.cpp:100] Creating Layer norm2
I1107 15:06:02.861225  3455 net.cpp:434] norm2 <- conv2
I1107 15:06:02.861229  3455 net.cpp:408] norm2 -> norm2
I1107 15:06:02.861340  3455 net.cpp:150] Setting up norm2
I1107 15:06:02.861346  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:02.861348  3455 net.cpp:165] Memory required for data: 1119068416
I1107 15:06:02.861351  3455 layer_factory.hpp:77] Creating layer pool2
I1107 15:06:02.861356  3455 net.cpp:100] Creating Layer pool2
I1107 15:06:02.861371  3455 net.cpp:434] pool2 <- norm2
I1107 15:06:02.861376  3455 net.cpp:408] pool2 -> pool2
I1107 15:06:02.861397  3455 net.cpp:150] Setting up pool2
I1107 15:06:02.861402  3455 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1107 15:06:02.861404  3455 net.cpp:165] Memory required for data: 1130144000
I1107 15:06:02.861407  3455 layer_factory.hpp:77] Creating layer conv3
I1107 15:06:02.861413  3455 net.cpp:100] Creating Layer conv3
I1107 15:06:02.861415  3455 net.cpp:434] conv3 <- pool2
I1107 15:06:02.861418  3455 net.cpp:408] conv3 -> conv3
I1107 15:06:02.863232  3455 net.cpp:150] Setting up conv3
I1107 15:06:02.863246  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.863250  3455 net.cpp:165] Memory required for data: 1152295168
I1107 15:06:02.863256  3455 layer_factory.hpp:77] Creating layer relu3
I1107 15:06:02.863262  3455 net.cpp:100] Creating Layer relu3
I1107 15:06:02.863265  3455 net.cpp:434] relu3 <- conv3
I1107 15:06:02.863270  3455 net.cpp:395] relu3 -> conv3 (in-place)
I1107 15:06:02.863435  3455 net.cpp:150] Setting up relu3
I1107 15:06:02.863445  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.863446  3455 net.cpp:165] Memory required for data: 1174446336
I1107 15:06:02.863450  3455 layer_factory.hpp:77] Creating layer conv4
I1107 15:06:02.863456  3455 net.cpp:100] Creating Layer conv4
I1107 15:06:02.863458  3455 net.cpp:434] conv4 <- conv3
I1107 15:06:02.863462  3455 net.cpp:408] conv4 -> conv4
I1107 15:06:02.867007  3455 net.cpp:150] Setting up conv4
I1107 15:06:02.867035  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.867038  3455 net.cpp:165] Memory required for data: 1196597504
I1107 15:06:02.867045  3455 layer_factory.hpp:77] Creating layer relu4
I1107 15:06:02.867053  3455 net.cpp:100] Creating Layer relu4
I1107 15:06:02.867058  3455 net.cpp:434] relu4 <- conv4
I1107 15:06:02.867063  3455 net.cpp:395] relu4 -> conv4 (in-place)
I1107 15:06:02.867172  3455 net.cpp:150] Setting up relu4
I1107 15:06:02.867179  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.867182  3455 net.cpp:165] Memory required for data: 1218748672
I1107 15:06:02.867184  3455 layer_factory.hpp:77] Creating layer conv5
I1107 15:06:02.867190  3455 net.cpp:100] Creating Layer conv5
I1107 15:06:02.867193  3455 net.cpp:434] conv5 <- conv4
I1107 15:06:02.867198  3455 net.cpp:408] conv5 -> conv5
I1107 15:06:02.870698  3455 net.cpp:150] Setting up conv5
I1107 15:06:02.870726  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.870729  3455 net.cpp:165] Memory required for data: 1240899840
I1107 15:06:02.870739  3455 layer_factory.hpp:77] Creating layer relu5
I1107 15:06:02.870748  3455 net.cpp:100] Creating Layer relu5
I1107 15:06:02.870751  3455 net.cpp:434] relu5 <- conv5
I1107 15:06:02.870757  3455 net.cpp:395] relu5 -> conv5 (in-place)
I1107 15:06:02.870867  3455 net.cpp:150] Setting up relu5
I1107 15:06:02.870873  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:02.870877  3455 net.cpp:165] Memory required for data: 1263051008
I1107 15:06:02.870878  3455 layer_factory.hpp:77] Creating layer pool5
I1107 15:06:02.870884  3455 net.cpp:100] Creating Layer pool5
I1107 15:06:02.870887  3455 net.cpp:434] pool5 <- conv5
I1107 15:06:02.870892  3455 net.cpp:408] pool5 -> pool5
I1107 15:06:02.870919  3455 net.cpp:150] Setting up pool5
I1107 15:06:02.870924  3455 net.cpp:157] Top shape: 64 512 6 6 (1179648)
I1107 15:06:02.870928  3455 net.cpp:165] Memory required for data: 1267769600
I1107 15:06:02.870929  3455 layer_factory.hpp:77] Creating layer fc6
I1107 15:06:02.870935  3455 net.cpp:100] Creating Layer fc6
I1107 15:06:02.870939  3455 net.cpp:434] fc6 <- pool5
I1107 15:06:02.870944  3455 net.cpp:408] fc6 -> fc6
I1107 15:06:02.962960  3455 net.cpp:150] Setting up fc6
I1107 15:06:02.962990  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:02.962992  3455 net.cpp:165] Memory required for data: 1268818176
I1107 15:06:02.962999  3455 layer_factory.hpp:77] Creating layer relu6
I1107 15:06:02.963008  3455 net.cpp:100] Creating Layer relu6
I1107 15:06:02.963027  3455 net.cpp:434] relu6 <- fc6
I1107 15:06:02.963032  3455 net.cpp:395] relu6 -> fc6 (in-place)
I1107 15:06:02.963258  3455 net.cpp:150] Setting up relu6
I1107 15:06:02.963268  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:02.963270  3455 net.cpp:165] Memory required for data: 1269866752
I1107 15:06:02.963274  3455 layer_factory.hpp:77] Creating layer drop6
I1107 15:06:02.963279  3455 net.cpp:100] Creating Layer drop6
I1107 15:06:02.963281  3455 net.cpp:434] drop6 <- fc6
I1107 15:06:02.963285  3455 net.cpp:395] drop6 -> fc6 (in-place)
I1107 15:06:02.963306  3455 net.cpp:150] Setting up drop6
I1107 15:06:02.963311  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:02.963313  3455 net.cpp:165] Memory required for data: 1270915328
I1107 15:06:02.963316  3455 layer_factory.hpp:77] Creating layer fc7
I1107 15:06:02.963321  3455 net.cpp:100] Creating Layer fc7
I1107 15:06:02.963325  3455 net.cpp:434] fc7 <- fc6
I1107 15:06:02.963327  3455 net.cpp:408] fc7 -> fc7
I1107 15:06:02.973713  3455 net.cpp:150] Setting up fc7
I1107 15:06:02.973742  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:02.973744  3455 net.cpp:165] Memory required for data: 1271439616
I1107 15:06:02.973752  3455 layer_factory.hpp:77] Creating layer relu7
I1107 15:06:02.973762  3455 net.cpp:100] Creating Layer relu7
I1107 15:06:02.973765  3455 net.cpp:434] relu7 <- fc7
I1107 15:06:02.973770  3455 net.cpp:395] relu7 -> fc7 (in-place)
I1107 15:06:02.974033  3455 net.cpp:150] Setting up relu7
I1107 15:06:02.974042  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:02.974045  3455 net.cpp:165] Memory required for data: 1271963904
I1107 15:06:02.974047  3455 layer_factory.hpp:77] Creating layer drop7
I1107 15:06:02.974053  3455 net.cpp:100] Creating Layer drop7
I1107 15:06:02.974056  3455 net.cpp:434] drop7 <- fc7
I1107 15:06:02.974059  3455 net.cpp:395] drop7 -> fc7 (in-place)
I1107 15:06:02.974079  3455 net.cpp:150] Setting up drop7
I1107 15:06:02.974084  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:02.974087  3455 net.cpp:165] Memory required for data: 1272488192
I1107 15:06:02.974089  3455 layer_factory.hpp:77] Creating layer fc8_hmdb
I1107 15:06:02.974094  3455 net.cpp:100] Creating Layer fc8_hmdb
I1107 15:06:02.974097  3455 net.cpp:434] fc8_hmdb <- fc7
I1107 15:06:02.974102  3455 net.cpp:408] fc8_hmdb -> fc8
I1107 15:06:02.974449  3455 net.cpp:150] Setting up fc8_hmdb
I1107 15:06:02.974458  3455 net.cpp:157] Top shape: 64 51 (3264)
I1107 15:06:02.974462  3455 net.cpp:165] Memory required for data: 1272501248
I1107 15:06:02.974465  3455 layer_factory.hpp:77] Creating layer loss
I1107 15:06:02.974470  3455 net.cpp:100] Creating Layer loss
I1107 15:06:02.974473  3455 net.cpp:434] loss <- fc8
I1107 15:06:02.974476  3455 net.cpp:434] loss <- label
I1107 15:06:02.974481  3455 net.cpp:408] loss -> loss
I1107 15:06:02.974491  3455 layer_factory.hpp:77] Creating layer loss
I1107 15:06:02.974720  3455 net.cpp:150] Setting up loss
I1107 15:06:02.974730  3455 net.cpp:157] Top shape: (1)
I1107 15:06:02.974731  3455 net.cpp:160]     with loss weight 1
I1107 15:06:02.974742  3455 net.cpp:165] Memory required for data: 1272501252
I1107 15:06:02.974745  3455 net.cpp:226] loss needs backward computation.
I1107 15:06:02.974748  3455 net.cpp:226] fc8_hmdb needs backward computation.
I1107 15:06:02.974750  3455 net.cpp:226] drop7 needs backward computation.
I1107 15:06:02.974752  3455 net.cpp:226] relu7 needs backward computation.
I1107 15:06:02.974755  3455 net.cpp:226] fc7 needs backward computation.
I1107 15:06:02.974757  3455 net.cpp:226] drop6 needs backward computation.
I1107 15:06:02.974759  3455 net.cpp:226] relu6 needs backward computation.
I1107 15:06:02.974762  3455 net.cpp:226] fc6 needs backward computation.
I1107 15:06:02.974764  3455 net.cpp:226] pool5 needs backward computation.
I1107 15:06:02.974767  3455 net.cpp:226] relu5 needs backward computation.
I1107 15:06:02.974769  3455 net.cpp:226] conv5 needs backward computation.
I1107 15:06:02.974772  3455 net.cpp:226] relu4 needs backward computation.
I1107 15:06:02.974784  3455 net.cpp:226] conv4 needs backward computation.
I1107 15:06:02.974787  3455 net.cpp:226] relu3 needs backward computation.
I1107 15:06:02.974791  3455 net.cpp:226] conv3 needs backward computation.
I1107 15:06:02.974792  3455 net.cpp:226] pool2 needs backward computation.
I1107 15:06:02.974795  3455 net.cpp:226] norm2 needs backward computation.
I1107 15:06:02.974797  3455 net.cpp:226] relu2 needs backward computation.
I1107 15:06:02.974800  3455 net.cpp:226] conv2 needs backward computation.
I1107 15:06:02.974802  3455 net.cpp:226] pool1 needs backward computation.
I1107 15:06:02.974805  3455 net.cpp:226] norm1 needs backward computation.
I1107 15:06:02.974807  3455 net.cpp:226] relu1 needs backward computation.
I1107 15:06:02.974810  3455 net.cpp:226] conv1 needs backward computation.
I1107 15:06:02.974813  3455 net.cpp:228] train_data does not need backward computation.
I1107 15:06:02.974815  3455 net.cpp:270] This network produces output loss
I1107 15:06:02.974825  3455 net.cpp:283] Network initialization done.
I1107 15:06:02.975167  3455 solver.cpp:181] Creating test net (#0) specified by net file: mywork/hmdb51/vgg_m_2048_net.prototxt
I1107 15:06:02.975199  3455 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_data
I1107 15:06:02.975332  3455 net.cpp:58] Initializing net from parameters: 
name: "VGG_CNN_M_2048"
state {
  phase: TEST
}
layer {
  name: "test_data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/hadoop/whx/dataset/hmdb/jpg_output/hmdb51_val_lmdb/split1"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 5
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_hmdb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 100
  }
  param {
    lr_mult: 100
  }
  inner_product_param {
    num_output: 51
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1107 15:06:02.975411  3455 layer_factory.hpp:77] Creating layer test_data
I1107 15:06:02.975473  3455 net.cpp:100] Creating Layer test_data
I1107 15:06:02.975479  3455 net.cpp:408] test_data -> data
I1107 15:06:02.975486  3455 net.cpp:408] test_data -> label
I1107 15:06:02.976017  3468 db_lmdb.cpp:35] Opened lmdb /home/hadoop/whx/dataset/hmdb/jpg_output/hmdb51_val_lmdb/split1
I1107 15:06:02.976183  3455 data_layer.cpp:41] output data size: 64,3,224,224
I1107 15:06:03.015192  3455 net.cpp:150] Setting up test_data
I1107 15:06:03.015216  3455 net.cpp:157] Top shape: 64 3 224 224 (9633792)
I1107 15:06:03.015223  3455 net.cpp:157] Top shape: 64 (64)
I1107 15:06:03.015225  3455 net.cpp:165] Memory required for data: 38535424
I1107 15:06:03.015230  3455 layer_factory.hpp:77] Creating layer label_test_data_1_split
I1107 15:06:03.015240  3455 net.cpp:100] Creating Layer label_test_data_1_split
I1107 15:06:03.015244  3455 net.cpp:434] label_test_data_1_split <- label
I1107 15:06:03.015249  3455 net.cpp:408] label_test_data_1_split -> label_test_data_1_split_0
I1107 15:06:03.015256  3455 net.cpp:408] label_test_data_1_split -> label_test_data_1_split_1
I1107 15:06:03.015326  3455 net.cpp:150] Setting up label_test_data_1_split
I1107 15:06:03.015333  3455 net.cpp:157] Top shape: 64 (64)
I1107 15:06:03.015336  3455 net.cpp:157] Top shape: 64 (64)
I1107 15:06:03.015338  3455 net.cpp:165] Memory required for data: 38535936
I1107 15:06:03.015341  3455 layer_factory.hpp:77] Creating layer conv1
I1107 15:06:03.015349  3455 net.cpp:100] Creating Layer conv1
I1107 15:06:03.015352  3455 net.cpp:434] conv1 <- data
I1107 15:06:03.015357  3455 net.cpp:408] conv1 -> conv1
I1107 15:06:03.019749  3455 net.cpp:150] Setting up conv1
I1107 15:06:03.019759  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:03.019763  3455 net.cpp:165] Memory required for data: 330523392
I1107 15:06:03.019770  3455 layer_factory.hpp:77] Creating layer relu1
I1107 15:06:03.019776  3455 net.cpp:100] Creating Layer relu1
I1107 15:06:03.019779  3455 net.cpp:434] relu1 <- conv1
I1107 15:06:03.019783  3455 net.cpp:395] relu1 -> conv1 (in-place)
I1107 15:06:03.019893  3455 net.cpp:150] Setting up relu1
I1107 15:06:03.019901  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:03.019904  3455 net.cpp:165] Memory required for data: 622510848
I1107 15:06:03.019906  3455 layer_factory.hpp:77] Creating layer norm1
I1107 15:06:03.019914  3455 net.cpp:100] Creating Layer norm1
I1107 15:06:03.019917  3455 net.cpp:434] norm1 <- conv1
I1107 15:06:03.019922  3455 net.cpp:408] norm1 -> norm1
I1107 15:06:03.020117  3455 net.cpp:150] Setting up norm1
I1107 15:06:03.020124  3455 net.cpp:157] Top shape: 64 96 109 109 (72996864)
I1107 15:06:03.020128  3455 net.cpp:165] Memory required for data: 914498304
I1107 15:06:03.020130  3455 layer_factory.hpp:77] Creating layer pool1
I1107 15:06:03.020136  3455 net.cpp:100] Creating Layer pool1
I1107 15:06:03.020139  3455 net.cpp:434] pool1 <- norm1
I1107 15:06:03.020143  3455 net.cpp:408] pool1 -> pool1
I1107 15:06:03.020169  3455 net.cpp:150] Setting up pool1
I1107 15:06:03.020175  3455 net.cpp:157] Top shape: 64 96 54 54 (17915904)
I1107 15:06:03.020179  3455 net.cpp:165] Memory required for data: 986161920
I1107 15:06:03.020180  3455 layer_factory.hpp:77] Creating layer conv2
I1107 15:06:03.020186  3455 net.cpp:100] Creating Layer conv2
I1107 15:06:03.020190  3455 net.cpp:434] conv2 <- pool1
I1107 15:06:03.020203  3455 net.cpp:408] conv2 -> conv2
I1107 15:06:03.021551  3455 net.cpp:150] Setting up conv2
I1107 15:06:03.021570  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:03.021574  3455 net.cpp:165] Memory required for data: 1030464256
I1107 15:06:03.021581  3455 layer_factory.hpp:77] Creating layer relu2
I1107 15:06:03.021589  3455 net.cpp:100] Creating Layer relu2
I1107 15:06:03.021592  3455 net.cpp:434] relu2 <- conv2
I1107 15:06:03.021596  3455 net.cpp:395] relu2 -> conv2 (in-place)
I1107 15:06:03.021715  3455 net.cpp:150] Setting up relu2
I1107 15:06:03.021723  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:03.021725  3455 net.cpp:165] Memory required for data: 1074766592
I1107 15:06:03.021728  3455 layer_factory.hpp:77] Creating layer norm2
I1107 15:06:03.021736  3455 net.cpp:100] Creating Layer norm2
I1107 15:06:03.021739  3455 net.cpp:434] norm2 <- conv2
I1107 15:06:03.021744  3455 net.cpp:408] norm2 -> norm2
I1107 15:06:03.021939  3455 net.cpp:150] Setting up norm2
I1107 15:06:03.021950  3455 net.cpp:157] Top shape: 64 256 26 26 (11075584)
I1107 15:06:03.021953  3455 net.cpp:165] Memory required for data: 1119068928
I1107 15:06:03.021955  3455 layer_factory.hpp:77] Creating layer pool2
I1107 15:06:03.021960  3455 net.cpp:100] Creating Layer pool2
I1107 15:06:03.021963  3455 net.cpp:434] pool2 <- norm2
I1107 15:06:03.021967  3455 net.cpp:408] pool2 -> pool2
I1107 15:06:03.021992  3455 net.cpp:150] Setting up pool2
I1107 15:06:03.021997  3455 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1107 15:06:03.022001  3455 net.cpp:165] Memory required for data: 1130144512
I1107 15:06:03.022002  3455 layer_factory.hpp:77] Creating layer conv3
I1107 15:06:03.022011  3455 net.cpp:100] Creating Layer conv3
I1107 15:06:03.022013  3455 net.cpp:434] conv3 <- pool2
I1107 15:06:03.022017  3455 net.cpp:408] conv3 -> conv3
I1107 15:06:03.024111  3455 net.cpp:150] Setting up conv3
I1107 15:06:03.024132  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.024137  3455 net.cpp:165] Memory required for data: 1152295680
I1107 15:06:03.024145  3455 layer_factory.hpp:77] Creating layer relu3
I1107 15:06:03.024154  3455 net.cpp:100] Creating Layer relu3
I1107 15:06:03.024158  3455 net.cpp:434] relu3 <- conv3
I1107 15:06:03.024163  3455 net.cpp:395] relu3 -> conv3 (in-place)
I1107 15:06:03.024273  3455 net.cpp:150] Setting up relu3
I1107 15:06:03.024281  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.024283  3455 net.cpp:165] Memory required for data: 1174446848
I1107 15:06:03.024286  3455 layer_factory.hpp:77] Creating layer conv4
I1107 15:06:03.024293  3455 net.cpp:100] Creating Layer conv4
I1107 15:06:03.024296  3455 net.cpp:434] conv4 <- conv3
I1107 15:06:03.024301  3455 net.cpp:408] conv4 -> conv4
I1107 15:06:03.028256  3455 net.cpp:150] Setting up conv4
I1107 15:06:03.028278  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.028282  3455 net.cpp:165] Memory required for data: 1196598016
I1107 15:06:03.028288  3455 layer_factory.hpp:77] Creating layer relu4
I1107 15:06:03.028297  3455 net.cpp:100] Creating Layer relu4
I1107 15:06:03.028301  3455 net.cpp:434] relu4 <- conv4
I1107 15:06:03.028306  3455 net.cpp:395] relu4 -> conv4 (in-place)
I1107 15:06:03.028415  3455 net.cpp:150] Setting up relu4
I1107 15:06:03.028422  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.028425  3455 net.cpp:165] Memory required for data: 1218749184
I1107 15:06:03.028427  3455 layer_factory.hpp:77] Creating layer conv5
I1107 15:06:03.028434  3455 net.cpp:100] Creating Layer conv5
I1107 15:06:03.028437  3455 net.cpp:434] conv5 <- conv4
I1107 15:06:03.028441  3455 net.cpp:408] conv5 -> conv5
I1107 15:06:03.032459  3455 net.cpp:150] Setting up conv5
I1107 15:06:03.032482  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.032485  3455 net.cpp:165] Memory required for data: 1240900352
I1107 15:06:03.032495  3455 layer_factory.hpp:77] Creating layer relu5
I1107 15:06:03.032505  3455 net.cpp:100] Creating Layer relu5
I1107 15:06:03.032526  3455 net.cpp:434] relu5 <- conv5
I1107 15:06:03.032532  3455 net.cpp:395] relu5 -> conv5 (in-place)
I1107 15:06:03.032716  3455 net.cpp:150] Setting up relu5
I1107 15:06:03.032726  3455 net.cpp:157] Top shape: 64 512 13 13 (5537792)
I1107 15:06:03.032728  3455 net.cpp:165] Memory required for data: 1263051520
I1107 15:06:03.032730  3455 layer_factory.hpp:77] Creating layer pool5
I1107 15:06:03.032739  3455 net.cpp:100] Creating Layer pool5
I1107 15:06:03.032742  3455 net.cpp:434] pool5 <- conv5
I1107 15:06:03.032747  3455 net.cpp:408] pool5 -> pool5
I1107 15:06:03.032778  3455 net.cpp:150] Setting up pool5
I1107 15:06:03.032784  3455 net.cpp:157] Top shape: 64 512 6 6 (1179648)
I1107 15:06:03.032786  3455 net.cpp:165] Memory required for data: 1267770112
I1107 15:06:03.032789  3455 layer_factory.hpp:77] Creating layer fc6
I1107 15:06:03.032794  3455 net.cpp:100] Creating Layer fc6
I1107 15:06:03.032796  3455 net.cpp:434] fc6 <- pool5
I1107 15:06:03.032800  3455 net.cpp:408] fc6 -> fc6
I1107 15:06:03.132228  3455 net.cpp:150] Setting up fc6
I1107 15:06:03.132256  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:03.132259  3455 net.cpp:165] Memory required for data: 1268818688
I1107 15:06:03.132266  3455 layer_factory.hpp:77] Creating layer relu6
I1107 15:06:03.132277  3455 net.cpp:100] Creating Layer relu6
I1107 15:06:03.132280  3455 net.cpp:434] relu6 <- fc6
I1107 15:06:03.132285  3455 net.cpp:395] relu6 -> fc6 (in-place)
I1107 15:06:03.132546  3455 net.cpp:150] Setting up relu6
I1107 15:06:03.132555  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:03.132557  3455 net.cpp:165] Memory required for data: 1269867264
I1107 15:06:03.132560  3455 layer_factory.hpp:77] Creating layer drop6
I1107 15:06:03.132566  3455 net.cpp:100] Creating Layer drop6
I1107 15:06:03.132568  3455 net.cpp:434] drop6 <- fc6
I1107 15:06:03.132575  3455 net.cpp:395] drop6 -> fc6 (in-place)
I1107 15:06:03.132593  3455 net.cpp:150] Setting up drop6
I1107 15:06:03.132598  3455 net.cpp:157] Top shape: 64 4096 (262144)
I1107 15:06:03.132601  3455 net.cpp:165] Memory required for data: 1270915840
I1107 15:06:03.132602  3455 layer_factory.hpp:77] Creating layer fc7
I1107 15:06:03.132608  3455 net.cpp:100] Creating Layer fc7
I1107 15:06:03.132611  3455 net.cpp:434] fc7 <- fc6
I1107 15:06:03.132614  3455 net.cpp:408] fc7 -> fc7
I1107 15:06:03.142946  3455 net.cpp:150] Setting up fc7
I1107 15:06:03.142974  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:03.142977  3455 net.cpp:165] Memory required for data: 1271440128
I1107 15:06:03.142984  3455 layer_factory.hpp:77] Creating layer relu7
I1107 15:06:03.142995  3455 net.cpp:100] Creating Layer relu7
I1107 15:06:03.142999  3455 net.cpp:434] relu7 <- fc7
I1107 15:06:03.143003  3455 net.cpp:395] relu7 -> fc7 (in-place)
I1107 15:06:03.143268  3455 net.cpp:150] Setting up relu7
I1107 15:06:03.143276  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:03.143280  3455 net.cpp:165] Memory required for data: 1271964416
I1107 15:06:03.143282  3455 layer_factory.hpp:77] Creating layer drop7
I1107 15:06:03.143288  3455 net.cpp:100] Creating Layer drop7
I1107 15:06:03.143291  3455 net.cpp:434] drop7 <- fc7
I1107 15:06:03.143295  3455 net.cpp:395] drop7 -> fc7 (in-place)
I1107 15:06:03.143313  3455 net.cpp:150] Setting up drop7
I1107 15:06:03.143317  3455 net.cpp:157] Top shape: 64 2048 (131072)
I1107 15:06:03.143319  3455 net.cpp:165] Memory required for data: 1272488704
I1107 15:06:03.143322  3455 layer_factory.hpp:77] Creating layer fc8_hmdb
I1107 15:06:03.143327  3455 net.cpp:100] Creating Layer fc8_hmdb
I1107 15:06:03.143329  3455 net.cpp:434] fc8_hmdb <- fc7
I1107 15:06:03.143334  3455 net.cpp:408] fc8_hmdb -> fc8
I1107 15:06:03.143471  3455 net.cpp:150] Setting up fc8_hmdb
I1107 15:06:03.143479  3455 net.cpp:157] Top shape: 64 51 (3264)
I1107 15:06:03.143481  3455 net.cpp:165] Memory required for data: 1272501760
I1107 15:06:03.143486  3455 layer_factory.hpp:77] Creating layer fc8_fc8_hmdb_0_split
I1107 15:06:03.143491  3455 net.cpp:100] Creating Layer fc8_fc8_hmdb_0_split
I1107 15:06:03.143503  3455 net.cpp:434] fc8_fc8_hmdb_0_split <- fc8
I1107 15:06:03.143507  3455 net.cpp:408] fc8_fc8_hmdb_0_split -> fc8_fc8_hmdb_0_split_0
I1107 15:06:03.143513  3455 net.cpp:408] fc8_fc8_hmdb_0_split -> fc8_fc8_hmdb_0_split_1
I1107 15:06:03.143537  3455 net.cpp:150] Setting up fc8_fc8_hmdb_0_split
I1107 15:06:03.143542  3455 net.cpp:157] Top shape: 64 51 (3264)
I1107 15:06:03.143544  3455 net.cpp:157] Top shape: 64 51 (3264)
I1107 15:06:03.143546  3455 net.cpp:165] Memory required for data: 1272527872
I1107 15:06:03.143548  3455 layer_factory.hpp:77] Creating layer loss
I1107 15:06:03.143559  3455 net.cpp:100] Creating Layer loss
I1107 15:06:03.143563  3455 net.cpp:434] loss <- fc8_fc8_hmdb_0_split_0
I1107 15:06:03.143565  3455 net.cpp:434] loss <- label_test_data_1_split_0
I1107 15:06:03.143569  3455 net.cpp:408] loss -> loss
I1107 15:06:03.143575  3455 layer_factory.hpp:77] Creating layer loss
I1107 15:06:03.143733  3455 net.cpp:150] Setting up loss
I1107 15:06:03.143743  3455 net.cpp:157] Top shape: (1)
I1107 15:06:03.143744  3455 net.cpp:160]     with loss weight 1
I1107 15:06:03.143753  3455 net.cpp:165] Memory required for data: 1272527876
I1107 15:06:03.143754  3455 layer_factory.hpp:77] Creating layer accuracy
I1107 15:06:03.143759  3455 net.cpp:100] Creating Layer accuracy
I1107 15:06:03.143762  3455 net.cpp:434] accuracy <- fc8_fc8_hmdb_0_split_1
I1107 15:06:03.143765  3455 net.cpp:434] accuracy <- label_test_data_1_split_1
I1107 15:06:03.143769  3455 net.cpp:408] accuracy -> accuracy
I1107 15:06:03.143775  3455 net.cpp:150] Setting up accuracy
I1107 15:06:03.143779  3455 net.cpp:157] Top shape: (1)
I1107 15:06:03.143780  3455 net.cpp:165] Memory required for data: 1272527880
I1107 15:06:03.143784  3455 net.cpp:228] accuracy does not need backward computation.
I1107 15:06:03.143785  3455 net.cpp:226] loss needs backward computation.
I1107 15:06:03.143788  3455 net.cpp:226] fc8_fc8_hmdb_0_split needs backward computation.
I1107 15:06:03.143791  3455 net.cpp:226] fc8_hmdb needs backward computation.
I1107 15:06:03.143793  3455 net.cpp:226] drop7 needs backward computation.
I1107 15:06:03.143795  3455 net.cpp:226] relu7 needs backward computation.
I1107 15:06:03.143797  3455 net.cpp:226] fc7 needs backward computation.
I1107 15:06:03.143800  3455 net.cpp:226] drop6 needs backward computation.
I1107 15:06:03.143802  3455 net.cpp:226] relu6 needs backward computation.
I1107 15:06:03.143805  3455 net.cpp:226] fc6 needs backward computation.
I1107 15:06:03.143807  3455 net.cpp:226] pool5 needs backward computation.
I1107 15:06:03.143810  3455 net.cpp:226] relu5 needs backward computation.
I1107 15:06:03.143812  3455 net.cpp:226] conv5 needs backward computation.
I1107 15:06:03.143815  3455 net.cpp:226] relu4 needs backward computation.
I1107 15:06:03.143817  3455 net.cpp:226] conv4 needs backward computation.
I1107 15:06:03.143821  3455 net.cpp:226] relu3 needs backward computation.
I1107 15:06:03.143822  3455 net.cpp:226] conv3 needs backward computation.
I1107 15:06:03.143826  3455 net.cpp:226] pool2 needs backward computation.
I1107 15:06:03.143827  3455 net.cpp:226] norm2 needs backward computation.
I1107 15:06:03.143831  3455 net.cpp:226] relu2 needs backward computation.
I1107 15:06:03.143832  3455 net.cpp:226] conv2 needs backward computation.
I1107 15:06:03.143836  3455 net.cpp:226] pool1 needs backward computation.
I1107 15:06:03.143837  3455 net.cpp:226] norm1 needs backward computation.
I1107 15:06:03.143841  3455 net.cpp:226] relu1 needs backward computation.
I1107 15:06:03.143842  3455 net.cpp:226] conv1 needs backward computation.
I1107 15:06:03.143846  3455 net.cpp:228] label_test_data_1_split does not need backward computation.
I1107 15:06:03.143849  3455 net.cpp:228] test_data does not need backward computation.
I1107 15:06:03.143852  3455 net.cpp:270] This network produces output accuracy
I1107 15:06:03.143854  3455 net.cpp:270] This network produces output loss
I1107 15:06:03.143867  3455 net.cpp:283] Network initialization done.
I1107 15:06:03.143925  3455 solver.cpp:60] Solver scaffolding done.
I1107 15:06:03.144282  3455 caffe.cpp:251] Starting Optimization
I1107 15:06:03.144287  3455 solver.cpp:279] Solving VGG_CNN_M_2048
I1107 15:06:03.144290  3455 solver.cpp:280] Learning Rate Policy: step
I1107 15:06:03.145153  3455 solver.cpp:337] Iteration 0, Testing net (#0)
I1107 15:06:03.145161  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:06:30.817440  3455 solver.cpp:404]     Test net output #0: accuracy = 0.021875
I1107 15:06:30.817466  3455 solver.cpp:404]     Test net output #1: loss = 3.93834 (* 1 = 3.93834 loss)
I1107 15:06:30.971565  3455 solver.cpp:228] Iteration 0, loss = 3.93183
I1107 15:06:30.971590  3455 solver.cpp:244]     Train net output #0: loss = 3.93183 (* 1 = 3.93183 loss)
I1107 15:06:30.971599  3455 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I1107 15:06:45.561506  3467 blocking_queue.cpp:50] Waiting for data
I1107 15:06:47.198853  3455 blocking_queue.cpp:50] Data layer prefetch queue empty
I1107 15:10:46.905709  3455 solver.cpp:337] Iteration 500, Testing net (#0)
I1107 15:10:46.905778  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:11:14.873852  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614063
I1107 15:11:14.873884  3455 solver.cpp:404]     Test net output #1: loss = 3.88542 (* 1 = 3.88542 loss)
I1107 15:11:15.011734  3455 solver.cpp:228] Iteration 500, loss = 3.83856
I1107 15:11:15.011768  3455 solver.cpp:244]     Train net output #0: loss = 3.83856 (* 1 = 3.83856 loss)
I1107 15:11:15.011775  3455 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I1107 15:15:27.754202  3455 solver.cpp:337] Iteration 1000, Testing net (#0)
I1107 15:15:27.754266  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:15:55.725565  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0597656
I1107 15:15:55.725597  3455 solver.cpp:404]     Test net output #1: loss = 3.85473 (* 1 = 3.85473 loss)
I1107 15:15:55.863792  3455 solver.cpp:228] Iteration 1000, loss = 3.85892
I1107 15:15:55.863826  3455 solver.cpp:244]     Train net output #0: loss = 3.85892 (* 1 = 3.85892 loss)
I1107 15:15:55.863834  3455 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I1107 15:20:08.609120  3455 solver.cpp:337] Iteration 1500, Testing net (#0)
I1107 15:20:08.609182  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:20:36.561810  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585938
I1107 15:20:36.561838  3455 solver.cpp:404]     Test net output #1: loss = 3.87765 (* 1 = 3.87765 loss)
I1107 15:20:36.700141  3455 solver.cpp:228] Iteration 1500, loss = 3.80806
I1107 15:20:36.700170  3455 solver.cpp:244]     Train net output #0: loss = 3.80806 (* 1 = 3.80806 loss)
I1107 15:20:36.700176  3455 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I1107 15:24:49.399888  3455 solver.cpp:337] Iteration 2000, Testing net (#0)
I1107 15:24:49.399940  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:25:17.344454  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0613281
I1107 15:25:17.344483  3455 solver.cpp:404]     Test net output #1: loss = 3.85579 (* 1 = 3.85579 loss)
I1107 15:25:17.482933  3455 solver.cpp:228] Iteration 2000, loss = 3.9024
I1107 15:25:17.482959  3455 solver.cpp:244]     Train net output #0: loss = 3.9024 (* 1 = 3.9024 loss)
I1107 15:25:17.482965  3455 sgd_solver.cpp:106] Iteration 2000, lr = 1e-06
I1107 15:29:30.169561  3455 solver.cpp:337] Iteration 2500, Testing net (#0)
I1107 15:29:30.169620  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:29:58.121754  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0604687
I1107 15:29:58.121780  3455 solver.cpp:404]     Test net output #1: loss = 3.87352 (* 1 = 3.87352 loss)
I1107 15:29:58.259708  3455 solver.cpp:228] Iteration 2500, loss = 3.90376
I1107 15:29:58.259734  3455 solver.cpp:244]     Train net output #0: loss = 3.90376 (* 1 = 3.90376 loss)
I1107 15:29:58.259742  3455 sgd_solver.cpp:106] Iteration 2500, lr = 1e-06
I1107 15:34:10.971520  3455 solver.cpp:337] Iteration 3000, Testing net (#0)
I1107 15:34:10.971585  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:34:38.919602  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0582031
I1107 15:34:38.919631  3455 solver.cpp:404]     Test net output #1: loss = 3.85907 (* 1 = 3.85907 loss)
I1107 15:34:39.057711  3455 solver.cpp:228] Iteration 3000, loss = 3.8361
I1107 15:34:39.057741  3455 solver.cpp:244]     Train net output #0: loss = 3.8361 (* 1 = 3.8361 loss)
I1107 15:34:39.057749  3455 sgd_solver.cpp:106] Iteration 3000, lr = 1e-07
I1107 15:38:51.794371  3455 solver.cpp:337] Iteration 3500, Testing net (#0)
I1107 15:38:51.794428  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:39:19.742352  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0630469
I1107 15:39:19.742378  3455 solver.cpp:404]     Test net output #1: loss = 3.86944 (* 1 = 3.86944 loss)
I1107 15:39:19.880988  3455 solver.cpp:228] Iteration 3500, loss = 3.95958
I1107 15:39:19.881016  3455 solver.cpp:244]     Train net output #0: loss = 3.95958 (* 1 = 3.95958 loss)
I1107 15:39:19.881022  3455 sgd_solver.cpp:106] Iteration 3500, lr = 1e-07
I1107 15:43:32.643355  3455 solver.cpp:337] Iteration 4000, Testing net (#0)
I1107 15:43:32.643419  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:44:00.593479  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607031
I1107 15:44:00.593509  3455 solver.cpp:404]     Test net output #1: loss = 3.88468 (* 1 = 3.88468 loss)
I1107 15:44:00.731940  3455 solver.cpp:228] Iteration 4000, loss = 3.8922
I1107 15:44:00.731971  3455 solver.cpp:244]     Train net output #0: loss = 3.8922 (* 1 = 3.8922 loss)
I1107 15:44:00.731979  3455 sgd_solver.cpp:106] Iteration 4000, lr = 1e-08
I1107 15:48:13.481585  3455 solver.cpp:337] Iteration 4500, Testing net (#0)
I1107 15:48:13.481650  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:48:41.421814  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0588281
I1107 15:48:41.421844  3455 solver.cpp:404]     Test net output #1: loss = 3.88306 (* 1 = 3.88306 loss)
I1107 15:48:41.559768  3455 solver.cpp:228] Iteration 4500, loss = 3.80673
I1107 15:48:41.559801  3455 solver.cpp:244]     Train net output #0: loss = 3.80673 (* 1 = 3.80673 loss)
I1107 15:48:41.559810  3455 sgd_solver.cpp:106] Iteration 4500, lr = 1e-08
I1107 15:52:54.302431  3455 solver.cpp:337] Iteration 5000, Testing net (#0)
I1107 15:52:54.302505  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:53:22.254094  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607031
I1107 15:53:22.254125  3455 solver.cpp:404]     Test net output #1: loss = 3.85803 (* 1 = 3.85803 loss)
I1107 15:53:22.392731  3455 solver.cpp:228] Iteration 5000, loss = 3.88099
I1107 15:53:22.392763  3455 solver.cpp:244]     Train net output #0: loss = 3.88099 (* 1 = 3.88099 loss)
I1107 15:53:22.392771  3455 sgd_solver.cpp:106] Iteration 5000, lr = 1e-09
I1107 15:57:35.190260  3455 solver.cpp:337] Iteration 5500, Testing net (#0)
I1107 15:57:35.190323  3455 net.cpp:693] Ignoring source layer train_data
I1107 15:58:03.143628  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0600781
I1107 15:58:03.143657  3455 solver.cpp:404]     Test net output #1: loss = 3.87355 (* 1 = 3.87355 loss)
I1107 15:58:03.282070  3455 solver.cpp:228] Iteration 5500, loss = 3.83143
I1107 15:58:03.282099  3455 solver.cpp:244]     Train net output #0: loss = 3.83143 (* 1 = 3.83143 loss)
I1107 15:58:03.282106  3455 sgd_solver.cpp:106] Iteration 5500, lr = 1e-09
I1107 16:02:16.034117  3455 solver.cpp:337] Iteration 6000, Testing net (#0)
I1107 16:02:16.034174  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:02:43.977097  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0620313
I1107 16:02:43.977131  3455 solver.cpp:404]     Test net output #1: loss = 3.89821 (* 1 = 3.89821 loss)
I1107 16:02:44.115397  3455 solver.cpp:228] Iteration 6000, loss = 3.87172
I1107 16:02:44.115432  3455 solver.cpp:244]     Train net output #0: loss = 3.87172 (* 1 = 3.87172 loss)
I1107 16:02:44.115442  3455 sgd_solver.cpp:106] Iteration 6000, lr = 1e-10
I1107 16:06:56.836380  3455 solver.cpp:337] Iteration 6500, Testing net (#0)
I1107 16:06:56.836447  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:07:24.779688  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1107 16:07:24.779718  3455 solver.cpp:404]     Test net output #1: loss = 3.86351 (* 1 = 3.86351 loss)
I1107 16:07:24.917220  3455 solver.cpp:228] Iteration 6500, loss = 3.95076
I1107 16:07:24.917251  3455 solver.cpp:244]     Train net output #0: loss = 3.95076 (* 1 = 3.95076 loss)
I1107 16:07:24.917258  3455 sgd_solver.cpp:106] Iteration 6500, lr = 1e-10
I1107 16:11:37.645825  3455 solver.cpp:337] Iteration 7000, Testing net (#0)
I1107 16:11:37.645884  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:12:05.596514  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0588281
I1107 16:12:05.596547  3455 solver.cpp:404]     Test net output #1: loss = 3.854 (* 1 = 3.854 loss)
I1107 16:12:05.735199  3455 solver.cpp:228] Iteration 7000, loss = 3.7949
I1107 16:12:05.735235  3455 solver.cpp:244]     Train net output #0: loss = 3.7949 (* 1 = 3.7949 loss)
I1107 16:12:05.735244  3455 sgd_solver.cpp:106] Iteration 7000, lr = 1e-11
I1107 16:16:18.439446  3455 solver.cpp:337] Iteration 7500, Testing net (#0)
I1107 16:16:18.439499  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:16:46.392141  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607031
I1107 16:16:46.392171  3455 solver.cpp:404]     Test net output #1: loss = 3.85071 (* 1 = 3.85071 loss)
I1107 16:16:46.530319  3455 solver.cpp:228] Iteration 7500, loss = 3.79897
I1107 16:16:46.530349  3455 solver.cpp:244]     Train net output #0: loss = 3.79897 (* 1 = 3.79897 loss)
I1107 16:16:46.530356  3455 sgd_solver.cpp:106] Iteration 7500, lr = 1e-11
I1107 16:20:59.259618  3455 solver.cpp:337] Iteration 8000, Testing net (#0)
I1107 16:20:59.259671  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:21:27.205994  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1107 16:21:27.206022  3455 solver.cpp:404]     Test net output #1: loss = 3.88724 (* 1 = 3.88724 loss)
I1107 16:21:27.344233  3455 solver.cpp:228] Iteration 8000, loss = 3.90813
I1107 16:21:27.344264  3455 solver.cpp:244]     Train net output #0: loss = 3.90813 (* 1 = 3.90813 loss)
I1107 16:21:27.344274  3455 sgd_solver.cpp:106] Iteration 8000, lr = 1e-12
I1107 16:25:40.042498  3455 solver.cpp:337] Iteration 8500, Testing net (#0)
I1107 16:25:40.042551  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:26:07.987709  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0592969
I1107 16:26:07.987740  3455 solver.cpp:404]     Test net output #1: loss = 3.8607 (* 1 = 3.8607 loss)
I1107 16:26:08.125838  3455 solver.cpp:228] Iteration 8500, loss = 3.85782
I1107 16:26:08.125870  3455 solver.cpp:244]     Train net output #0: loss = 3.85782 (* 1 = 3.85782 loss)
I1107 16:26:08.125877  3455 sgd_solver.cpp:106] Iteration 8500, lr = 1e-12
I1107 16:30:20.861382  3455 solver.cpp:337] Iteration 9000, Testing net (#0)
I1107 16:30:20.861444  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:30:48.811692  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0627344
I1107 16:30:48.811727  3455 solver.cpp:404]     Test net output #1: loss = 3.87127 (* 1 = 3.87127 loss)
I1107 16:30:48.950587  3455 solver.cpp:228] Iteration 9000, loss = 3.83569
I1107 16:30:48.950623  3455 solver.cpp:244]     Train net output #0: loss = 3.83569 (* 1 = 3.83569 loss)
I1107 16:30:48.950631  3455 sgd_solver.cpp:106] Iteration 9000, lr = 1e-13
I1107 16:35:01.683966  3455 solver.cpp:337] Iteration 9500, Testing net (#0)
I1107 16:35:01.684023  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:35:29.623721  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617188
I1107 16:35:29.623749  3455 solver.cpp:404]     Test net output #1: loss = 3.85319 (* 1 = 3.85319 loss)
I1107 16:35:29.761464  3455 solver.cpp:228] Iteration 9500, loss = 3.90861
I1107 16:35:29.761497  3455 solver.cpp:244]     Train net output #0: loss = 3.90861 (* 1 = 3.90861 loss)
I1107 16:35:29.761504  3455 sgd_solver.cpp:106] Iteration 9500, lr = 1e-13
I1107 16:39:42.531035  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_10000.caffemodel
I1107 16:40:12.583853  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_10000.solverstate
I1107 16:40:14.965384  3455 solver.cpp:337] Iteration 10000, Testing net (#0)
I1107 16:40:14.965436  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:40:42.555243  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0576563
I1107 16:40:42.555275  3455 solver.cpp:404]     Test net output #1: loss = 3.88766 (* 1 = 3.88766 loss)
I1107 16:40:42.693262  3455 solver.cpp:228] Iteration 10000, loss = 3.93392
I1107 16:40:42.693336  3455 solver.cpp:244]     Train net output #0: loss = 3.93392 (* 1 = 3.93392 loss)
I1107 16:40:42.693347  3455 sgd_solver.cpp:106] Iteration 10000, lr = 1e-14
I1107 16:44:55.344589  3455 solver.cpp:337] Iteration 10500, Testing net (#0)
I1107 16:44:55.344657  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:45:23.303194  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0616406
I1107 16:45:23.303231  3455 solver.cpp:404]     Test net output #1: loss = 3.85699 (* 1 = 3.85699 loss)
I1107 16:45:23.441334  3455 solver.cpp:228] Iteration 10500, loss = 3.90772
I1107 16:45:23.441370  3455 solver.cpp:244]     Train net output #0: loss = 3.90772 (* 1 = 3.90772 loss)
I1107 16:45:23.441378  3455 sgd_solver.cpp:106] Iteration 10500, lr = 1e-14
I1107 16:49:36.096485  3455 solver.cpp:337] Iteration 11000, Testing net (#0)
I1107 16:49:36.096550  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:50:04.044950  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0597656
I1107 16:50:04.044983  3455 solver.cpp:404]     Test net output #1: loss = 3.85545 (* 1 = 3.85545 loss)
I1107 16:50:04.182981  3455 solver.cpp:228] Iteration 11000, loss = 3.78356
I1107 16:50:04.183012  3455 solver.cpp:244]     Train net output #0: loss = 3.78356 (* 1 = 3.78356 loss)
I1107 16:50:04.183019  3455 sgd_solver.cpp:106] Iteration 11000, lr = 1e-15
I1107 16:54:16.908478  3455 solver.cpp:337] Iteration 11500, Testing net (#0)
I1107 16:54:16.908535  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:54:44.847843  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0620313
I1107 16:54:44.847878  3455 solver.cpp:404]     Test net output #1: loss = 3.87018 (* 1 = 3.87018 loss)
I1107 16:54:44.986672  3455 solver.cpp:228] Iteration 11500, loss = 3.88601
I1107 16:54:44.986709  3455 solver.cpp:244]     Train net output #0: loss = 3.88601 (* 1 = 3.88601 loss)
I1107 16:54:44.986718  3455 sgd_solver.cpp:106] Iteration 11500, lr = 1e-15
I1107 16:58:57.671512  3455 solver.cpp:337] Iteration 12000, Testing net (#0)
I1107 16:58:57.671566  3455 net.cpp:693] Ignoring source layer train_data
I1107 16:59:25.623883  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0601562
I1107 16:59:25.623917  3455 solver.cpp:404]     Test net output #1: loss = 3.87499 (* 1 = 3.87499 loss)
I1107 16:59:25.762150  3455 solver.cpp:228] Iteration 12000, loss = 3.82248
I1107 16:59:25.762179  3455 solver.cpp:244]     Train net output #0: loss = 3.82248 (* 1 = 3.82248 loss)
I1107 16:59:25.762187  3455 sgd_solver.cpp:106] Iteration 12000, lr = 1e-16
I1107 17:03:38.389061  3455 solver.cpp:337] Iteration 12500, Testing net (#0)
I1107 17:03:38.389127  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:04:06.343147  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0583594
I1107 17:04:06.343179  3455 solver.cpp:404]     Test net output #1: loss = 3.85552 (* 1 = 3.85552 loss)
I1107 17:04:06.481421  3455 solver.cpp:228] Iteration 12500, loss = 3.85029
I1107 17:04:06.481454  3455 solver.cpp:244]     Train net output #0: loss = 3.85029 (* 1 = 3.85029 loss)
I1107 17:04:06.481462  3455 sgd_solver.cpp:106] Iteration 12500, lr = 1e-16
I1107 17:08:19.193662  3455 solver.cpp:337] Iteration 13000, Testing net (#0)
I1107 17:08:19.193733  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:08:47.148463  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06
I1107 17:08:47.148494  3455 solver.cpp:404]     Test net output #1: loss = 3.86432 (* 1 = 3.86432 loss)
I1107 17:08:47.287088  3455 solver.cpp:228] Iteration 13000, loss = 5.05639
I1107 17:08:47.287119  3455 solver.cpp:244]     Train net output #0: loss = 5.05639 (* 1 = 5.05639 loss)
I1107 17:08:47.287127  3455 sgd_solver.cpp:106] Iteration 13000, lr = 1e-17
I1107 17:12:59.989301  3455 solver.cpp:337] Iteration 13500, Testing net (#0)
I1107 17:13:00.015573  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:13:27.947979  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0592969
I1107 17:13:27.948014  3455 solver.cpp:404]     Test net output #1: loss = 3.86305 (* 1 = 3.86305 loss)
I1107 17:13:28.086220  3455 solver.cpp:228] Iteration 13500, loss = 3.80218
I1107 17:13:28.086253  3455 solver.cpp:244]     Train net output #0: loss = 3.80218 (* 1 = 3.80218 loss)
I1107 17:13:28.086261  3455 sgd_solver.cpp:106] Iteration 13500, lr = 1e-17
I1107 17:17:40.877182  3455 solver.cpp:337] Iteration 14000, Testing net (#0)
I1107 17:17:40.877245  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:18:08.849439  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1107 17:18:08.849469  3455 solver.cpp:404]     Test net output #1: loss = 3.86972 (* 1 = 3.86972 loss)
I1107 17:18:08.987637  3455 solver.cpp:228] Iteration 14000, loss = 3.84397
I1107 17:18:08.987668  3455 solver.cpp:244]     Train net output #0: loss = 3.84397 (* 1 = 3.84397 loss)
I1107 17:18:08.987676  3455 sgd_solver.cpp:106] Iteration 14000, lr = 1e-18
I1107 17:22:21.746840  3455 solver.cpp:337] Iteration 14500, Testing net (#0)
I1107 17:22:21.746897  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:22:49.711570  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1107 17:22:49.711597  3455 solver.cpp:404]     Test net output #1: loss = 3.89769 (* 1 = 3.89769 loss)
I1107 17:22:49.849424  3455 solver.cpp:228] Iteration 14500, loss = 3.75636
I1107 17:22:49.849452  3455 solver.cpp:244]     Train net output #0: loss = 3.75636 (* 1 = 3.75636 loss)
I1107 17:22:49.849459  3455 sgd_solver.cpp:106] Iteration 14500, lr = 1e-18
I1107 17:27:02.572814  3455 solver.cpp:337] Iteration 15000, Testing net (#0)
I1107 17:27:02.572870  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:27:30.542137  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614063
I1107 17:27:30.542170  3455 solver.cpp:404]     Test net output #1: loss = 3.87538 (* 1 = 3.87538 loss)
I1107 17:27:30.680281  3455 solver.cpp:228] Iteration 15000, loss = 3.84753
I1107 17:27:30.680311  3455 solver.cpp:244]     Train net output #0: loss = 3.84753 (* 1 = 3.84753 loss)
I1107 17:27:30.680317  3455 sgd_solver.cpp:106] Iteration 15000, lr = 1e-19
I1107 17:31:43.430546  3455 solver.cpp:337] Iteration 15500, Testing net (#0)
I1107 17:31:43.430604  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:32:11.396414  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1107 17:32:11.396446  3455 solver.cpp:404]     Test net output #1: loss = 3.86585 (* 1 = 3.86585 loss)
I1107 17:32:11.534641  3455 solver.cpp:228] Iteration 15500, loss = 3.86797
I1107 17:32:11.534670  3455 solver.cpp:244]     Train net output #0: loss = 3.86797 (* 1 = 3.86797 loss)
I1107 17:32:11.534677  3455 sgd_solver.cpp:106] Iteration 15500, lr = 1e-19
I1107 17:36:24.295120  3455 solver.cpp:337] Iteration 16000, Testing net (#0)
I1107 17:36:24.295176  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:36:52.253598  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585156
I1107 17:36:52.253626  3455 solver.cpp:404]     Test net output #1: loss = 3.86024 (* 1 = 3.86024 loss)
I1107 17:36:52.391705  3455 solver.cpp:228] Iteration 16000, loss = 3.87997
I1107 17:36:52.391733  3455 solver.cpp:244]     Train net output #0: loss = 3.87997 (* 1 = 3.87997 loss)
I1107 17:36:52.391739  3455 sgd_solver.cpp:106] Iteration 16000, lr = 1e-20
I1107 17:41:05.154232  3455 solver.cpp:337] Iteration 16500, Testing net (#0)
I1107 17:41:05.154301  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:41:33.127454  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0621875
I1107 17:41:33.127483  3455 solver.cpp:404]     Test net output #1: loss = 3.85304 (* 1 = 3.85304 loss)
I1107 17:41:33.265580  3455 solver.cpp:228] Iteration 16500, loss = 3.7924
I1107 17:41:33.265612  3455 solver.cpp:244]     Train net output #0: loss = 3.7924 (* 1 = 3.7924 loss)
I1107 17:41:33.265619  3455 sgd_solver.cpp:106] Iteration 16500, lr = 1e-20
I1107 17:45:46.042870  3455 solver.cpp:337] Iteration 17000, Testing net (#0)
I1107 17:45:46.042940  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:46:14.006276  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1107 17:46:14.006307  3455 solver.cpp:404]     Test net output #1: loss = 3.86987 (* 1 = 3.86987 loss)
I1107 17:46:14.144788  3455 solver.cpp:228] Iteration 17000, loss = 3.83603
I1107 17:46:14.144819  3455 solver.cpp:244]     Train net output #0: loss = 3.83603 (* 1 = 3.83603 loss)
I1107 17:46:14.144827  3455 sgd_solver.cpp:106] Iteration 17000, lr = 1e-21
I1107 17:50:26.884862  3455 solver.cpp:337] Iteration 17500, Testing net (#0)
I1107 17:50:26.884919  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:50:54.856184  3455 solver.cpp:404]     Test net output #0: accuracy = 0.060625
I1107 17:50:54.856210  3455 solver.cpp:404]     Test net output #1: loss = 3.86857 (* 1 = 3.86857 loss)
I1107 17:50:54.994774  3455 solver.cpp:228] Iteration 17500, loss = 3.83843
I1107 17:50:54.994803  3455 solver.cpp:244]     Train net output #0: loss = 3.83843 (* 1 = 3.83843 loss)
I1107 17:50:54.994810  3455 sgd_solver.cpp:106] Iteration 17500, lr = 1e-21
I1107 17:55:07.734999  3455 solver.cpp:337] Iteration 18000, Testing net (#0)
I1107 17:55:07.735059  3455 net.cpp:693] Ignoring source layer train_data
I1107 17:55:35.704197  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0576563
I1107 17:55:35.704228  3455 solver.cpp:404]     Test net output #1: loss = 3.88158 (* 1 = 3.88158 loss)
I1107 17:55:35.842213  3455 solver.cpp:228] Iteration 18000, loss = 3.75885
I1107 17:55:35.842243  3455 solver.cpp:244]     Train net output #0: loss = 3.75885 (* 1 = 3.75885 loss)
I1107 17:55:35.842250  3455 sgd_solver.cpp:106] Iteration 18000, lr = 1e-22
I1107 17:59:48.638831  3455 solver.cpp:337] Iteration 18500, Testing net (#0)
I1107 17:59:48.638893  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:00:16.605849  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06125
I1107 18:00:16.605880  3455 solver.cpp:404]     Test net output #1: loss = 3.85934 (* 1 = 3.85934 loss)
I1107 18:00:16.744205  3455 solver.cpp:228] Iteration 18500, loss = 3.9094
I1107 18:00:16.744235  3455 solver.cpp:244]     Train net output #0: loss = 3.9094 (* 1 = 3.9094 loss)
I1107 18:00:16.744242  3455 sgd_solver.cpp:106] Iteration 18500, lr = 1e-22
I1107 18:04:29.515094  3455 solver.cpp:337] Iteration 19000, Testing net (#0)
I1107 18:04:29.515143  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:04:57.483422  3455 solver.cpp:404]     Test net output #0: accuracy = 0.05875
I1107 18:04:57.483450  3455 solver.cpp:404]     Test net output #1: loss = 3.85471 (* 1 = 3.85471 loss)
I1107 18:04:57.622037  3455 solver.cpp:228] Iteration 19000, loss = 3.80862
I1107 18:04:57.622068  3455 solver.cpp:244]     Train net output #0: loss = 3.80862 (* 1 = 3.80862 loss)
I1107 18:04:57.622076  3455 sgd_solver.cpp:106] Iteration 19000, lr = 1e-23
I1107 18:09:10.379106  3455 solver.cpp:337] Iteration 19500, Testing net (#0)
I1107 18:09:10.379165  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:09:38.338603  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0625781
I1107 18:09:38.338634  3455 solver.cpp:404]     Test net output #1: loss = 3.85808 (* 1 = 3.85808 loss)
I1107 18:09:38.477133  3455 solver.cpp:228] Iteration 19500, loss = 3.87145
I1107 18:09:38.477164  3455 solver.cpp:244]     Train net output #0: loss = 3.87145 (* 1 = 3.87145 loss)
I1107 18:09:38.477169  3455 sgd_solver.cpp:106] Iteration 19500, lr = 1e-23
I1107 18:13:51.238119  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_20000.caffemodel
I1107 18:14:17.473307  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_20000.solverstate
I1107 18:14:19.785221  3455 solver.cpp:337] Iteration 20000, Testing net (#0)
I1107 18:14:19.785272  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:14:47.382730  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1107 18:14:47.382804  3455 solver.cpp:404]     Test net output #1: loss = 3.86966 (* 1 = 3.86966 loss)
I1107 18:14:47.520987  3455 solver.cpp:228] Iteration 20000, loss = 3.8891
I1107 18:14:47.521019  3455 solver.cpp:244]     Train net output #0: loss = 3.8891 (* 1 = 3.8891 loss)
I1107 18:14:47.521026  3455 sgd_solver.cpp:106] Iteration 20000, lr = 1e-24
I1107 18:19:00.250977  3455 solver.cpp:337] Iteration 20500, Testing net (#0)
I1107 18:19:00.251045  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:19:28.212546  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614844
I1107 18:19:28.212579  3455 solver.cpp:404]     Test net output #1: loss = 3.87094 (* 1 = 3.87094 loss)
I1107 18:19:28.350770  3455 solver.cpp:228] Iteration 20500, loss = 3.77874
I1107 18:19:28.350801  3455 solver.cpp:244]     Train net output #0: loss = 3.77874 (* 1 = 3.77874 loss)
I1107 18:19:28.350810  3455 sgd_solver.cpp:106] Iteration 20500, lr = 1e-24
I1107 18:23:41.102802  3455 solver.cpp:337] Iteration 21000, Testing net (#0)
I1107 18:23:41.102860  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:24:09.061986  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0602344
I1107 18:24:09.062017  3455 solver.cpp:404]     Test net output #1: loss = 3.88139 (* 1 = 3.88139 loss)
I1107 18:24:09.200372  3455 solver.cpp:228] Iteration 21000, loss = 3.90726
I1107 18:24:09.200400  3455 solver.cpp:244]     Train net output #0: loss = 3.90726 (* 1 = 3.90726 loss)
I1107 18:24:09.200407  3455 sgd_solver.cpp:106] Iteration 21000, lr = 1e-25
I1107 18:28:21.965991  3455 solver.cpp:337] Iteration 21500, Testing net (#0)
I1107 18:28:21.966051  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:28:49.929421  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0583594
I1107 18:28:49.929452  3455 solver.cpp:404]     Test net output #1: loss = 3.86364 (* 1 = 3.86364 loss)
I1107 18:28:50.067872  3455 solver.cpp:228] Iteration 21500, loss = 3.80875
I1107 18:28:50.067903  3455 solver.cpp:244]     Train net output #0: loss = 3.80875 (* 1 = 3.80875 loss)
I1107 18:28:50.067911  3455 sgd_solver.cpp:106] Iteration 21500, lr = 1e-25
I1107 18:33:02.790679  3455 solver.cpp:337] Iteration 22000, Testing net (#0)
I1107 18:33:02.790735  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:33:30.750742  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0628906
I1107 18:33:30.750779  3455 solver.cpp:404]     Test net output #1: loss = 3.85156 (* 1 = 3.85156 loss)
I1107 18:33:30.889106  3455 solver.cpp:228] Iteration 22000, loss = 3.80177
I1107 18:33:30.889140  3455 solver.cpp:244]     Train net output #0: loss = 3.80177 (* 1 = 3.80177 loss)
I1107 18:33:30.889150  3455 sgd_solver.cpp:106] Iteration 22000, lr = 1e-26
I1107 18:37:43.610883  3455 solver.cpp:337] Iteration 22500, Testing net (#0)
I1107 18:37:43.610937  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:38:11.566908  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06
I1107 18:38:11.566941  3455 solver.cpp:404]     Test net output #1: loss = 3.85858 (* 1 = 3.85858 loss)
I1107 18:38:11.705535  3455 solver.cpp:228] Iteration 22500, loss = 3.68835
I1107 18:38:11.705566  3455 solver.cpp:244]     Train net output #0: loss = 3.68835 (* 1 = 3.68835 loss)
I1107 18:38:11.705574  3455 sgd_solver.cpp:106] Iteration 22500, lr = 1e-26
I1107 18:42:24.492998  3455 solver.cpp:337] Iteration 23000, Testing net (#0)
I1107 18:42:24.493073  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:42:52.451825  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0616406
I1107 18:42:52.451856  3455 solver.cpp:404]     Test net output #1: loss = 3.85432 (* 1 = 3.85432 loss)
I1107 18:42:52.590471  3455 solver.cpp:228] Iteration 23000, loss = 3.87614
I1107 18:42:52.590502  3455 solver.cpp:244]     Train net output #0: loss = 3.87614 (* 1 = 3.87614 loss)
I1107 18:42:52.590509  3455 sgd_solver.cpp:106] Iteration 23000, lr = 1e-27
I1107 18:47:05.379832  3455 solver.cpp:337] Iteration 23500, Testing net (#0)
I1107 18:47:05.379886  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:47:33.344326  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585938
I1107 18:47:33.344354  3455 solver.cpp:404]     Test net output #1: loss = 3.88073 (* 1 = 3.88073 loss)
I1107 18:47:33.482239  3455 solver.cpp:228] Iteration 23500, loss = 3.85502
I1107 18:47:33.482267  3455 solver.cpp:244]     Train net output #0: loss = 3.85502 (* 1 = 3.85502 loss)
I1107 18:47:33.482273  3455 sgd_solver.cpp:106] Iteration 23500, lr = 1e-27
I1107 18:51:46.242458  3455 solver.cpp:337] Iteration 24000, Testing net (#0)
I1107 18:51:46.242509  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:52:14.203064  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1107 18:52:14.203095  3455 solver.cpp:404]     Test net output #1: loss = 3.85457 (* 1 = 3.85457 loss)
I1107 18:52:14.341560  3455 solver.cpp:228] Iteration 24000, loss = 3.88213
I1107 18:52:14.341593  3455 solver.cpp:244]     Train net output #0: loss = 3.88213 (* 1 = 3.88213 loss)
I1107 18:52:14.341600  3455 sgd_solver.cpp:106] Iteration 24000, lr = 1e-28
I1107 18:56:27.142583  3455 solver.cpp:337] Iteration 24500, Testing net (#0)
I1107 18:56:27.142645  3455 net.cpp:693] Ignoring source layer train_data
I1107 18:56:55.115542  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0567188
I1107 18:56:55.115572  3455 solver.cpp:404]     Test net output #1: loss = 3.86854 (* 1 = 3.86854 loss)
I1107 18:56:55.253643  3455 solver.cpp:228] Iteration 24500, loss = 3.85154
I1107 18:56:55.253671  3455 solver.cpp:244]     Train net output #0: loss = 3.85154 (* 1 = 3.85154 loss)
I1107 18:56:55.253679  3455 sgd_solver.cpp:106] Iteration 24500, lr = 1e-28
I1107 19:01:08.046986  3455 solver.cpp:337] Iteration 25000, Testing net (#0)
I1107 19:01:08.047057  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:01:36.020155  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0628906
I1107 19:01:36.020186  3455 solver.cpp:404]     Test net output #1: loss = 3.86434 (* 1 = 3.86434 loss)
I1107 19:01:36.158303  3455 solver.cpp:228] Iteration 25000, loss = 3.87111
I1107 19:01:36.158329  3455 solver.cpp:244]     Train net output #0: loss = 3.87111 (* 1 = 3.87111 loss)
I1107 19:01:36.158335  3455 sgd_solver.cpp:106] Iteration 25000, lr = 1e-29
I1107 19:05:48.934054  3455 solver.cpp:337] Iteration 25500, Testing net (#0)
I1107 19:05:48.934115  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:06:16.896595  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0586719
I1107 19:06:16.896627  3455 solver.cpp:404]     Test net output #1: loss = 3.87075 (* 1 = 3.87075 loss)
I1107 19:06:17.034755  3455 solver.cpp:228] Iteration 25500, loss = 3.80122
I1107 19:06:17.034785  3455 solver.cpp:244]     Train net output #0: loss = 3.80122 (* 1 = 3.80122 loss)
I1107 19:06:17.034793  3455 sgd_solver.cpp:106] Iteration 25500, lr = 1e-29
I1107 19:10:29.830801  3455 solver.cpp:337] Iteration 26000, Testing net (#0)
I1107 19:10:29.830859  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:10:57.798346  3455 solver.cpp:404]     Test net output #0: accuracy = 0.063125
I1107 19:10:57.798375  3455 solver.cpp:404]     Test net output #1: loss = 3.86817 (* 1 = 3.86817 loss)
I1107 19:10:57.937095  3455 solver.cpp:228] Iteration 26000, loss = 3.79337
I1107 19:10:57.937127  3455 solver.cpp:244]     Train net output #0: loss = 3.79337 (* 1 = 3.79337 loss)
I1107 19:10:57.937134  3455 sgd_solver.cpp:106] Iteration 26000, lr = 1e-30
I1107 19:15:10.689612  3455 solver.cpp:337] Iteration 26500, Testing net (#0)
I1107 19:15:10.689669  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:15:38.659085  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596094
I1107 19:15:38.659118  3455 solver.cpp:404]     Test net output #1: loss = 3.87704 (* 1 = 3.87704 loss)
I1107 19:15:38.797503  3455 solver.cpp:228] Iteration 26500, loss = 3.81194
I1107 19:15:38.797536  3455 solver.cpp:244]     Train net output #0: loss = 3.81194 (* 1 = 3.81194 loss)
I1107 19:15:38.797544  3455 sgd_solver.cpp:106] Iteration 26500, lr = 1e-30
I1107 19:19:51.544513  3455 solver.cpp:337] Iteration 27000, Testing net (#0)
I1107 19:19:51.544579  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:20:19.512490  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0582813
I1107 19:20:19.512518  3455 solver.cpp:404]     Test net output #1: loss = 3.87601 (* 1 = 3.87601 loss)
I1107 19:20:19.650893  3455 solver.cpp:228] Iteration 27000, loss = 3.92124
I1107 19:20:19.650923  3455 solver.cpp:244]     Train net output #0: loss = 3.92124 (* 1 = 3.92124 loss)
I1107 19:20:19.650929  3455 sgd_solver.cpp:106] Iteration 27000, lr = 1e-31
I1107 19:24:32.424695  3455 solver.cpp:337] Iteration 27500, Testing net (#0)
I1107 19:24:32.424757  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:25:00.387133  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0628906
I1107 19:25:00.387161  3455 solver.cpp:404]     Test net output #1: loss = 3.86314 (* 1 = 3.86314 loss)
I1107 19:25:00.525378  3455 solver.cpp:228] Iteration 27500, loss = 3.87757
I1107 19:25:00.525408  3455 solver.cpp:244]     Train net output #0: loss = 3.87757 (* 1 = 3.87757 loss)
I1107 19:25:00.525413  3455 sgd_solver.cpp:106] Iteration 27500, lr = 1e-31
I1107 19:29:13.300277  3455 solver.cpp:337] Iteration 28000, Testing net (#0)
I1107 19:29:13.300328  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:29:41.262550  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1107 19:29:41.262586  3455 solver.cpp:404]     Test net output #1: loss = 3.88623 (* 1 = 3.88623 loss)
I1107 19:29:41.400998  3455 solver.cpp:228] Iteration 28000, loss = 3.89128
I1107 19:29:41.401031  3455 solver.cpp:244]     Train net output #0: loss = 3.89128 (* 1 = 3.89128 loss)
I1107 19:29:41.401038  3455 sgd_solver.cpp:106] Iteration 28000, lr = 1e-32
I1107 19:33:54.128973  3455 solver.cpp:337] Iteration 28500, Testing net (#0)
I1107 19:33:54.129036  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:34:22.101821  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0605469
I1107 19:34:22.101853  3455 solver.cpp:404]     Test net output #1: loss = 3.89303 (* 1 = 3.89303 loss)
I1107 19:34:22.240130  3455 solver.cpp:228] Iteration 28500, loss = 3.81958
I1107 19:34:22.240159  3455 solver.cpp:244]     Train net output #0: loss = 3.81958 (* 1 = 3.81958 loss)
I1107 19:34:22.240165  3455 sgd_solver.cpp:106] Iteration 28500, lr = 1e-32
I1107 19:38:34.982640  3455 solver.cpp:337] Iteration 29000, Testing net (#0)
I1107 19:38:34.982704  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:39:02.938071  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0589062
I1107 19:39:02.938099  3455 solver.cpp:404]     Test net output #1: loss = 3.8671 (* 1 = 3.8671 loss)
I1107 19:39:03.075886  3455 solver.cpp:228] Iteration 29000, loss = 3.84269
I1107 19:39:03.075917  3455 solver.cpp:244]     Train net output #0: loss = 3.84269 (* 1 = 3.84269 loss)
I1107 19:39:03.075923  3455 sgd_solver.cpp:106] Iteration 29000, lr = 1e-33
I1107 19:43:15.815240  3455 solver.cpp:337] Iteration 29500, Testing net (#0)
I1107 19:43:15.815295  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:43:43.776108  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1107 19:43:43.776140  3455 solver.cpp:404]     Test net output #1: loss = 3.884 (* 1 = 3.884 loss)
I1107 19:43:43.914947  3455 solver.cpp:228] Iteration 29500, loss = 3.85256
I1107 19:43:43.914978  3455 solver.cpp:244]     Train net output #0: loss = 3.85256 (* 1 = 3.85256 loss)
I1107 19:43:43.914983  3455 sgd_solver.cpp:106] Iteration 29500, lr = 1e-33
I1107 19:47:56.721420  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_30000.caffemodel
I1107 19:48:21.140826  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_30000.solverstate
I1107 19:48:24.175355  3455 solver.cpp:337] Iteration 30000, Testing net (#0)
I1107 19:48:24.175405  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:48:51.765259  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0589062
I1107 19:48:51.765317  3455 solver.cpp:404]     Test net output #1: loss = 3.86415 (* 1 = 3.86415 loss)
I1107 19:48:51.903924  3455 solver.cpp:228] Iteration 30000, loss = 3.81834
I1107 19:48:51.903955  3455 solver.cpp:244]     Train net output #0: loss = 3.81834 (* 1 = 3.81834 loss)
I1107 19:48:51.903962  3455 sgd_solver.cpp:106] Iteration 30000, lr = 1e-34
I1107 19:53:04.651759  3455 solver.cpp:337] Iteration 30500, Testing net (#0)
I1107 19:53:04.651809  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:53:32.605993  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0626563
I1107 19:53:32.606021  3455 solver.cpp:404]     Test net output #1: loss = 3.86893 (* 1 = 3.86893 loss)
I1107 19:53:32.744278  3455 solver.cpp:228] Iteration 30500, loss = 3.85214
I1107 19:53:32.744307  3455 solver.cpp:244]     Train net output #0: loss = 3.85214 (* 1 = 3.85214 loss)
I1107 19:53:32.744314  3455 sgd_solver.cpp:106] Iteration 30500, lr = 1e-34
I1107 19:57:45.489800  3455 solver.cpp:337] Iteration 31000, Testing net (#0)
I1107 19:57:45.489863  3455 net.cpp:693] Ignoring source layer train_data
I1107 19:58:13.450536  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0567969
I1107 19:58:13.450573  3455 solver.cpp:404]     Test net output #1: loss = 3.8808 (* 1 = 3.8808 loss)
I1107 19:58:13.588696  3455 solver.cpp:228] Iteration 31000, loss = 3.74292
I1107 19:58:13.588728  3455 solver.cpp:244]     Train net output #0: loss = 3.74292 (* 1 = 3.74292 loss)
I1107 19:58:13.588737  3455 sgd_solver.cpp:106] Iteration 31000, lr = 1e-35
I1107 20:02:26.343930  3455 solver.cpp:337] Iteration 31500, Testing net (#0)
I1107 20:02:26.343987  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:02:54.308064  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06375
I1107 20:02:54.308089  3455 solver.cpp:404]     Test net output #1: loss = 3.86112 (* 1 = 3.86112 loss)
I1107 20:02:54.446039  3455 solver.cpp:228] Iteration 31500, loss = 3.74155
I1107 20:02:54.446071  3455 solver.cpp:244]     Train net output #0: loss = 3.74155 (* 1 = 3.74155 loss)
I1107 20:02:54.446079  3455 sgd_solver.cpp:106] Iteration 31500, lr = 1e-35
I1107 20:07:07.146332  3455 solver.cpp:337] Iteration 32000, Testing net (#0)
I1107 20:07:07.146385  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:07:35.102838  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0604687
I1107 20:07:35.102867  3455 solver.cpp:404]     Test net output #1: loss = 3.88281 (* 1 = 3.88281 loss)
I1107 20:07:35.240896  3455 solver.cpp:228] Iteration 32000, loss = 3.78164
I1107 20:07:35.240927  3455 solver.cpp:244]     Train net output #0: loss = 3.78164 (* 1 = 3.78164 loss)
I1107 20:07:35.240934  3455 sgd_solver.cpp:106] Iteration 32000, lr = 1e-36
I1107 20:11:47.990334  3455 solver.cpp:337] Iteration 32500, Testing net (#0)
I1107 20:11:47.990377  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:12:15.941037  3455 solver.cpp:404]     Test net output #0: accuracy = 0.05875
I1107 20:12:15.941067  3455 solver.cpp:404]     Test net output #1: loss = 3.87628 (* 1 = 3.87628 loss)
I1107 20:12:16.079262  3455 solver.cpp:228] Iteration 32500, loss = 3.9043
I1107 20:12:16.079295  3455 solver.cpp:244]     Train net output #0: loss = 3.9043 (* 1 = 3.9043 loss)
I1107 20:12:16.079303  3455 sgd_solver.cpp:106] Iteration 32500, lr = 1e-36
I1107 20:16:28.821117  3455 solver.cpp:337] Iteration 33000, Testing net (#0)
I1107 20:16:28.821192  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:16:56.791388  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06125
I1107 20:16:56.791419  3455 solver.cpp:404]     Test net output #1: loss = 3.87769 (* 1 = 3.87769 loss)
I1107 20:16:56.929477  3455 solver.cpp:228] Iteration 33000, loss = 3.78145
I1107 20:16:56.929508  3455 solver.cpp:244]     Train net output #0: loss = 3.78145 (* 1 = 3.78145 loss)
I1107 20:16:56.929515  3455 sgd_solver.cpp:106] Iteration 33000, lr = 1e-37
I1107 20:21:09.677155  3455 solver.cpp:337] Iteration 33500, Testing net (#0)
I1107 20:21:09.677204  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:21:37.635398  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1107 20:21:37.635431  3455 solver.cpp:404]     Test net output #1: loss = 3.85873 (* 1 = 3.85873 loss)
I1107 20:21:37.773672  3455 solver.cpp:228] Iteration 33500, loss = 5.10074
I1107 20:21:37.773705  3455 solver.cpp:244]     Train net output #0: loss = 5.10074 (* 1 = 5.10074 loss)
I1107 20:21:37.773713  3455 sgd_solver.cpp:106] Iteration 33500, lr = 1e-37
I1107 20:25:50.503219  3455 solver.cpp:337] Iteration 34000, Testing net (#0)
I1107 20:25:50.503268  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:26:18.462132  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1107 20:26:18.462160  3455 solver.cpp:404]     Test net output #1: loss = 3.85605 (* 1 = 3.85605 loss)
I1107 20:26:18.600637  3455 solver.cpp:228] Iteration 34000, loss = 3.83797
I1107 20:26:18.600666  3455 solver.cpp:244]     Train net output #0: loss = 3.83797 (* 1 = 3.83797 loss)
I1107 20:26:18.600672  3455 sgd_solver.cpp:106] Iteration 34000, lr = 1e-38
I1107 20:30:31.294579  3455 solver.cpp:337] Iteration 34500, Testing net (#0)
I1107 20:30:31.294639  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:30:59.240751  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1107 20:30:59.240783  3455 solver.cpp:404]     Test net output #1: loss = 3.88509 (* 1 = 3.88509 loss)
I1107 20:30:59.378613  3455 solver.cpp:228] Iteration 34500, loss = 3.85938
I1107 20:30:59.378644  3455 solver.cpp:244]     Train net output #0: loss = 3.85938 (* 1 = 3.85938 loss)
I1107 20:30:59.378651  3455 sgd_solver.cpp:106] Iteration 34500, lr = 1e-38
I1107 20:35:12.090353  3455 solver.cpp:337] Iteration 35000, Testing net (#0)
I1107 20:35:12.090412  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:35:40.064595  3455 solver.cpp:404]     Test net output #0: accuracy = 0.05875
I1107 20:35:40.064623  3455 solver.cpp:404]     Test net output #1: loss = 3.86504 (* 1 = 3.86504 loss)
I1107 20:35:40.202905  3455 solver.cpp:228] Iteration 35000, loss = 3.81947
I1107 20:35:40.202937  3455 solver.cpp:244]     Train net output #0: loss = 3.81947 (* 1 = 3.81947 loss)
I1107 20:35:40.202945  3455 sgd_solver.cpp:106] Iteration 35000, lr = 1e-39
I1107 20:39:52.958962  3455 solver.cpp:337] Iteration 35500, Testing net (#0)
I1107 20:39:52.959023  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:40:20.933193  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0599219
I1107 20:40:20.933220  3455 solver.cpp:404]     Test net output #1: loss = 3.86272 (* 1 = 3.86272 loss)
I1107 20:40:21.070888  3455 solver.cpp:228] Iteration 35500, loss = 3.76992
I1107 20:40:21.070919  3455 solver.cpp:244]     Train net output #0: loss = 3.76992 (* 1 = 3.76992 loss)
I1107 20:40:21.070926  3455 sgd_solver.cpp:106] Iteration 35500, lr = 1e-39
I1107 20:44:33.824687  3455 solver.cpp:337] Iteration 36000, Testing net (#0)
I1107 20:44:33.824726  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:45:01.817868  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1107 20:45:01.817899  3455 solver.cpp:404]     Test net output #1: loss = 3.86235 (* 1 = 3.86235 loss)
I1107 20:45:01.956560  3455 solver.cpp:228] Iteration 36000, loss = 3.88884
I1107 20:45:01.956593  3455 solver.cpp:244]     Train net output #0: loss = 3.88884 (* 1 = 3.88884 loss)
I1107 20:45:01.956601  3455 sgd_solver.cpp:106] Iteration 36000, lr = 9.99995e-41
I1107 20:49:14.761350  3455 solver.cpp:337] Iteration 36500, Testing net (#0)
I1107 20:49:14.761421  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:49:42.719856  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0578125
I1107 20:49:42.719885  3455 solver.cpp:404]     Test net output #1: loss = 3.88575 (* 1 = 3.88575 loss)
I1107 20:49:42.858048  3455 solver.cpp:228] Iteration 36500, loss = 3.76832
I1107 20:49:42.858079  3455 solver.cpp:244]     Train net output #0: loss = 3.76832 (* 1 = 3.76832 loss)
I1107 20:49:42.858086  3455 sgd_solver.cpp:106] Iteration 36500, lr = 9.99995e-41
I1107 20:53:55.637871  3455 solver.cpp:337] Iteration 37000, Testing net (#0)
I1107 20:53:55.637938  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:54:23.604467  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0630469
I1107 20:54:23.604493  3455 solver.cpp:404]     Test net output #1: loss = 3.86897 (* 1 = 3.86897 loss)
I1107 20:54:23.742219  3455 solver.cpp:228] Iteration 37000, loss = 3.8109
I1107 20:54:23.742249  3455 solver.cpp:244]     Train net output #0: loss = 3.8109 (* 1 = 3.8109 loss)
I1107 20:54:23.742255  3455 sgd_solver.cpp:106] Iteration 37000, lr = 9.99967e-42
I1107 20:58:36.473302  3455 solver.cpp:337] Iteration 37500, Testing net (#0)
I1107 20:58:36.473348  3455 net.cpp:693] Ignoring source layer train_data
I1107 20:59:04.438289  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0595312
I1107 20:59:04.438321  3455 solver.cpp:404]     Test net output #1: loss = 3.86731 (* 1 = 3.86731 loss)
I1107 20:59:04.576195  3455 solver.cpp:228] Iteration 37500, loss = 3.9105
I1107 20:59:04.576227  3455 solver.cpp:244]     Train net output #0: loss = 3.9105 (* 1 = 3.9105 loss)
I1107 20:59:04.576236  3455 sgd_solver.cpp:106] Iteration 37500, lr = 9.99967e-42
I1107 21:03:17.379649  3455 solver.cpp:337] Iteration 38000, Testing net (#0)
I1107 21:03:17.379693  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:03:45.340685  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1107 21:03:45.340716  3455 solver.cpp:404]     Test net output #1: loss = 3.86714 (* 1 = 3.86714 loss)
I1107 21:03:45.478457  3455 solver.cpp:228] Iteration 38000, loss = 3.82385
I1107 21:03:45.478490  3455 solver.cpp:244]     Train net output #0: loss = 3.82385 (* 1 = 3.82385 loss)
I1107 21:03:45.478498  3455 sgd_solver.cpp:106] Iteration 38000, lr = 1.00053e-42
I1107 21:07:58.217710  3455 solver.cpp:337] Iteration 38500, Testing net (#0)
I1107 21:07:58.217772  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:08:26.173188  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614063
I1107 21:08:26.173219  3455 solver.cpp:404]     Test net output #1: loss = 3.86433 (* 1 = 3.86433 loss)
I1107 21:08:26.314306  3455 solver.cpp:228] Iteration 38500, loss = 3.85473
I1107 21:08:26.314337  3455 solver.cpp:244]     Train net output #0: loss = 3.85473 (* 1 = 3.85473 loss)
I1107 21:08:26.314345  3455 sgd_solver.cpp:106] Iteration 38500, lr = 1.00053e-42
I1107 21:12:39.078991  3455 solver.cpp:337] Iteration 39000, Testing net (#0)
I1107 21:12:39.079041  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:13:07.042464  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0604687
I1107 21:13:07.042495  3455 solver.cpp:404]     Test net output #1: loss = 3.87328 (* 1 = 3.87328 loss)
I1107 21:13:07.180382  3455 solver.cpp:228] Iteration 39000, loss = 3.89446
I1107 21:13:07.180410  3455 solver.cpp:244]     Train net output #0: loss = 3.89446 (* 1 = 3.89446 loss)
I1107 21:13:07.180418  3455 sgd_solver.cpp:106] Iteration 39000, lr = 9.94922e-44
I1107 21:17:19.916131  3455 solver.cpp:337] Iteration 39500, Testing net (#0)
I1107 21:17:19.916187  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:17:47.892930  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1107 21:17:47.892961  3455 solver.cpp:404]     Test net output #1: loss = 3.89325 (* 1 = 3.89325 loss)
I1107 21:17:48.031258  3455 solver.cpp:228] Iteration 39500, loss = 3.83098
I1107 21:17:48.031289  3455 solver.cpp:244]     Train net output #0: loss = 3.83098 (* 1 = 3.83098 loss)
I1107 21:17:48.031296  3455 sgd_solver.cpp:106] Iteration 39500, lr = 9.94922e-44
I1107 21:22:00.789981  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_40000.caffemodel
I1107 21:22:27.161264  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_40000.solverstate
I1107 21:22:29.511171  3455 solver.cpp:337] Iteration 40000, Testing net (#0)
I1107 21:22:29.511224  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:22:57.129573  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596094
I1107 21:22:57.129672  3455 solver.cpp:404]     Test net output #1: loss = 3.86084 (* 1 = 3.86084 loss)
I1107 21:22:57.268512  3455 solver.cpp:228] Iteration 40000, loss = 3.81043
I1107 21:22:57.268548  3455 solver.cpp:244]     Train net output #0: loss = 3.81043 (* 1 = 3.81043 loss)
I1107 21:22:57.268558  3455 sgd_solver.cpp:106] Iteration 40000, lr = 9.80909e-45
I1107 21:27:09.995298  3455 solver.cpp:337] Iteration 40500, Testing net (#0)
I1107 21:27:09.995360  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:27:37.969029  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0580469
I1107 21:27:37.969063  3455 solver.cpp:404]     Test net output #1: loss = 3.88599 (* 1 = 3.88599 loss)
I1107 21:27:38.106029  3455 solver.cpp:228] Iteration 40500, loss = 3.7319
I1107 21:27:38.106057  3455 solver.cpp:244]     Train net output #0: loss = 3.7319 (* 1 = 3.7319 loss)
I1107 21:27:38.106065  3455 sgd_solver.cpp:106] Iteration 40500, lr = 9.80909e-45
I1107 21:31:50.899272  3455 solver.cpp:337] Iteration 41000, Testing net (#0)
I1107 21:31:50.899334  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:32:18.880000  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0621094
I1107 21:32:18.880033  3455 solver.cpp:404]     Test net output #1: loss = 3.86719 (* 1 = 3.86719 loss)
I1107 21:32:19.018967  3455 solver.cpp:228] Iteration 41000, loss = 3.89444
I1107 21:32:19.019013  3455 solver.cpp:244]     Train net output #0: loss = 3.89444 (* 1 = 3.89444 loss)
I1107 21:32:19.019021  3455 sgd_solver.cpp:106] Iteration 41000, lr = 1.4013e-45
I1107 21:36:31.768311  3455 solver.cpp:337] Iteration 41500, Testing net (#0)
I1107 21:36:31.768371  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:36:59.746567  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0603125
I1107 21:36:59.746594  3455 solver.cpp:404]     Test net output #1: loss = 3.88183 (* 1 = 3.88183 loss)
I1107 21:36:59.884948  3455 solver.cpp:228] Iteration 41500, loss = 3.85992
I1107 21:36:59.884979  3455 solver.cpp:244]     Train net output #0: loss = 3.85992 (* 1 = 3.85992 loss)
I1107 21:36:59.884986  3455 sgd_solver.cpp:106] Iteration 41500, lr = 1.4013e-45
I1107 21:41:12.695026  3455 solver.cpp:337] Iteration 42000, Testing net (#0)
I1107 21:41:12.695086  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:41:40.665050  3455 solver.cpp:404]     Test net output #0: accuracy = 0.05875
I1107 21:41:40.665081  3455 solver.cpp:404]     Test net output #1: loss = 3.85094 (* 1 = 3.85094 loss)
I1107 21:41:40.802944  3455 solver.cpp:228] Iteration 42000, loss = 3.79944
I1107 21:41:40.802973  3455 solver.cpp:244]     Train net output #0: loss = 3.79944 (* 1 = 3.79944 loss)
I1107 21:41:40.802980  3455 sgd_solver.cpp:106] Iteration 42000, lr = 0
I1107 21:45:53.579469  3455 solver.cpp:337] Iteration 42500, Testing net (#0)
I1107 21:45:53.579530  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:46:21.547019  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0628125
I1107 21:46:21.547046  3455 solver.cpp:404]     Test net output #1: loss = 3.86289 (* 1 = 3.86289 loss)
I1107 21:46:21.684722  3455 solver.cpp:228] Iteration 42500, loss = 3.78632
I1107 21:46:21.684751  3455 solver.cpp:244]     Train net output #0: loss = 3.78632 (* 1 = 3.78632 loss)
I1107 21:46:21.684757  3455 sgd_solver.cpp:106] Iteration 42500, lr = 0
I1107 21:50:34.473429  3455 solver.cpp:337] Iteration 43000, Testing net (#0)
I1107 21:50:34.473501  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:51:02.457752  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0601562
I1107 21:51:02.457782  3455 solver.cpp:404]     Test net output #1: loss = 3.86635 (* 1 = 3.86635 loss)
I1107 21:51:02.596180  3455 solver.cpp:228] Iteration 43000, loss = 3.89018
I1107 21:51:02.596210  3455 solver.cpp:244]     Train net output #0: loss = 3.89018 (* 1 = 3.89018 loss)
I1107 21:51:02.596216  3455 sgd_solver.cpp:106] Iteration 43000, lr = 0
I1107 21:55:15.363788  3455 solver.cpp:337] Iteration 43500, Testing net (#0)
I1107 21:55:15.370790  3455 net.cpp:693] Ignoring source layer train_data
I1107 21:55:43.347033  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0588281
I1107 21:55:43.347064  3455 solver.cpp:404]     Test net output #1: loss = 3.87665 (* 1 = 3.87665 loss)
I1107 21:55:43.485280  3455 solver.cpp:228] Iteration 43500, loss = 3.84937
I1107 21:55:43.485312  3455 solver.cpp:244]     Train net output #0: loss = 3.84937 (* 1 = 3.84937 loss)
I1107 21:55:43.485319  3455 sgd_solver.cpp:106] Iteration 43500, lr = 0
I1107 21:59:56.276065  3455 solver.cpp:337] Iteration 44000, Testing net (#0)
I1107 21:59:56.276113  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:00:24.260589  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0609375
I1107 22:00:24.260617  3455 solver.cpp:404]     Test net output #1: loss = 3.86428 (* 1 = 3.86428 loss)
I1107 22:00:24.399241  3455 solver.cpp:228] Iteration 44000, loss = 3.81309
I1107 22:00:24.399271  3455 solver.cpp:244]     Train net output #0: loss = 3.81309 (* 1 = 3.81309 loss)
I1107 22:00:24.399278  3455 sgd_solver.cpp:106] Iteration 44000, lr = 0
I1107 22:04:37.185098  3455 solver.cpp:337] Iteration 44500, Testing net (#0)
I1107 22:04:37.185144  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:05:05.175487  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1107 22:05:05.175514  3455 solver.cpp:404]     Test net output #1: loss = 3.86662 (* 1 = 3.86662 loss)
I1107 22:05:05.313562  3455 solver.cpp:228] Iteration 44500, loss = 3.8271
I1107 22:05:05.313592  3455 solver.cpp:244]     Train net output #0: loss = 3.8271 (* 1 = 3.8271 loss)
I1107 22:05:05.313599  3455 sgd_solver.cpp:106] Iteration 44500, lr = 0
I1107 22:09:18.119974  3455 solver.cpp:337] Iteration 45000, Testing net (#0)
I1107 22:09:18.120031  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:09:46.092775  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0621875
I1107 22:09:46.092808  3455 solver.cpp:404]     Test net output #1: loss = 3.85901 (* 1 = 3.85901 loss)
I1107 22:09:46.231156  3455 solver.cpp:228] Iteration 45000, loss = 3.85594
I1107 22:09:46.231189  3455 solver.cpp:244]     Train net output #0: loss = 3.85594 (* 1 = 3.85594 loss)
I1107 22:09:46.231195  3455 sgd_solver.cpp:106] Iteration 45000, lr = 0
I1107 22:13:59.025351  3455 solver.cpp:337] Iteration 45500, Testing net (#0)
I1107 22:13:59.025411  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:14:27.034937  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0604687
I1107 22:14:27.034965  3455 solver.cpp:404]     Test net output #1: loss = 3.86884 (* 1 = 3.86884 loss)
I1107 22:14:27.173892  3455 solver.cpp:228] Iteration 45500, loss = 3.84396
I1107 22:14:27.173920  3455 solver.cpp:244]     Train net output #0: loss = 3.84396 (* 1 = 3.84396 loss)
I1107 22:14:27.173926  3455 sgd_solver.cpp:106] Iteration 45500, lr = 0
I1107 22:18:40.007905  3455 solver.cpp:337] Iteration 46000, Testing net (#0)
I1107 22:18:40.007967  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:19:07.992022  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0582813
I1107 22:19:07.992049  3455 solver.cpp:404]     Test net output #1: loss = 3.89521 (* 1 = 3.89521 loss)
I1107 22:19:08.130726  3455 solver.cpp:228] Iteration 46000, loss = 3.82343
I1107 22:19:08.130754  3455 solver.cpp:244]     Train net output #0: loss = 3.82343 (* 1 = 3.82343 loss)
I1107 22:19:08.130760  3455 sgd_solver.cpp:106] Iteration 46000, lr = 0
I1107 22:23:21.354050  3455 solver.cpp:337] Iteration 46500, Testing net (#0)
I1107 22:23:21.354125  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:23:49.338341  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0603906
I1107 22:23:49.338374  3455 solver.cpp:404]     Test net output #1: loss = 3.87732 (* 1 = 3.87732 loss)
I1107 22:23:49.476197  3455 solver.cpp:228] Iteration 46500, loss = 3.82698
I1107 22:23:49.476230  3455 solver.cpp:244]     Train net output #0: loss = 3.82698 (* 1 = 3.82698 loss)
I1107 22:23:49.476238  3455 sgd_solver.cpp:106] Iteration 46500, lr = 0
I1107 22:28:02.243512  3455 solver.cpp:337] Iteration 47000, Testing net (#0)
I1107 22:28:02.243584  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:28:30.219632  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0602344
I1107 22:28:30.219667  3455 solver.cpp:404]     Test net output #1: loss = 3.86694 (* 1 = 3.86694 loss)
I1107 22:28:30.358021  3455 solver.cpp:228] Iteration 47000, loss = 3.88199
I1107 22:28:30.358052  3455 solver.cpp:244]     Train net output #0: loss = 3.88199 (* 1 = 3.88199 loss)
I1107 22:28:30.358059  3455 sgd_solver.cpp:106] Iteration 47000, lr = 0
I1107 22:32:43.159739  3455 solver.cpp:337] Iteration 47500, Testing net (#0)
I1107 22:32:43.159799  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:33:11.149154  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0592969
I1107 22:33:11.149186  3455 solver.cpp:404]     Test net output #1: loss = 3.87887 (* 1 = 3.87887 loss)
I1107 22:33:11.287262  3455 solver.cpp:228] Iteration 47500, loss = 3.81924
I1107 22:33:11.287295  3455 solver.cpp:244]     Train net output #0: loss = 3.81924 (* 1 = 3.81924 loss)
I1107 22:33:11.287302  3455 sgd_solver.cpp:106] Iteration 47500, lr = 0
I1107 22:37:24.066674  3455 solver.cpp:337] Iteration 48000, Testing net (#0)
I1107 22:37:24.066742  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:37:52.045385  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0626563
I1107 22:37:52.045415  3455 solver.cpp:404]     Test net output #1: loss = 3.86505 (* 1 = 3.86505 loss)
I1107 22:37:52.183107  3455 solver.cpp:228] Iteration 48000, loss = 3.78031
I1107 22:37:52.183138  3455 solver.cpp:244]     Train net output #0: loss = 3.78031 (* 1 = 3.78031 loss)
I1107 22:37:52.183146  3455 sgd_solver.cpp:106] Iteration 48000, lr = 0
I1107 22:42:04.940665  3455 solver.cpp:337] Iteration 48500, Testing net (#0)
I1107 22:42:04.940739  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:42:32.934068  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1107 22:42:32.934105  3455 solver.cpp:404]     Test net output #1: loss = 3.84812 (* 1 = 3.84812 loss)
I1107 22:42:33.072975  3455 solver.cpp:228] Iteration 48500, loss = 3.80287
I1107 22:42:33.073011  3455 solver.cpp:244]     Train net output #0: loss = 3.80287 (* 1 = 3.80287 loss)
I1107 22:42:33.073020  3455 sgd_solver.cpp:106] Iteration 48500, lr = 0
I1107 22:46:45.830648  3455 solver.cpp:337] Iteration 49000, Testing net (#0)
I1107 22:46:45.830708  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:47:13.809633  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0579688
I1107 22:47:13.809664  3455 solver.cpp:404]     Test net output #1: loss = 3.87389 (* 1 = 3.87389 loss)
I1107 22:47:13.947664  3455 solver.cpp:228] Iteration 49000, loss = 3.92557
I1107 22:47:13.947695  3455 solver.cpp:244]     Train net output #0: loss = 3.92557 (* 1 = 3.92557 loss)
I1107 22:47:13.947702  3455 sgd_solver.cpp:106] Iteration 49000, lr = 0
I1107 22:51:26.733816  3455 solver.cpp:337] Iteration 49500, Testing net (#0)
I1107 22:51:26.733883  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:51:54.718034  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617969
I1107 22:51:54.718063  3455 solver.cpp:404]     Test net output #1: loss = 3.87586 (* 1 = 3.87586 loss)
I1107 22:51:54.856935  3455 solver.cpp:228] Iteration 49500, loss = 3.85723
I1107 22:51:54.856968  3455 solver.cpp:244]     Train net output #0: loss = 3.85723 (* 1 = 3.85723 loss)
I1107 22:51:54.856976  3455 sgd_solver.cpp:106] Iteration 49500, lr = 0
I1107 22:56:07.621034  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_50000.caffemodel
I1107 22:56:41.286186  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_50000.solverstate
I1107 22:56:43.529125  3455 solver.cpp:337] Iteration 50000, Testing net (#0)
I1107 22:56:43.529176  3455 net.cpp:693] Ignoring source layer train_data
I1107 22:57:11.151700  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1107 22:57:11.151729  3455 solver.cpp:404]     Test net output #1: loss = 3.87446 (* 1 = 3.87446 loss)
I1107 22:57:11.290127  3455 solver.cpp:228] Iteration 50000, loss = 3.8107
I1107 22:57:11.290197  3455 solver.cpp:244]     Train net output #0: loss = 3.8107 (* 1 = 3.8107 loss)
I1107 22:57:11.290206  3455 sgd_solver.cpp:106] Iteration 50000, lr = 0
I1107 23:01:24.064260  3455 solver.cpp:337] Iteration 50500, Testing net (#0)
I1107 23:01:24.064321  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:01:52.045313  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617188
I1107 23:01:52.045351  3455 solver.cpp:404]     Test net output #1: loss = 3.87799 (* 1 = 3.87799 loss)
I1107 23:01:52.183562  3455 solver.cpp:228] Iteration 50500, loss = 5.11015
I1107 23:01:52.183596  3455 solver.cpp:244]     Train net output #0: loss = 5.11015 (* 1 = 5.11015 loss)
I1107 23:01:52.183605  3455 sgd_solver.cpp:106] Iteration 50500, lr = 0
I1107 23:06:05.005872  3455 solver.cpp:337] Iteration 51000, Testing net (#0)
I1107 23:06:05.005930  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:06:32.984948  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607813
I1107 23:06:32.984982  3455 solver.cpp:404]     Test net output #1: loss = 3.86253 (* 1 = 3.86253 loss)
I1107 23:06:33.122737  3455 solver.cpp:228] Iteration 51000, loss = 3.81658
I1107 23:06:33.122764  3455 solver.cpp:244]     Train net output #0: loss = 3.81658 (* 1 = 3.81658 loss)
I1107 23:06:33.122772  3455 sgd_solver.cpp:106] Iteration 51000, lr = 0
I1107 23:10:45.952586  3455 solver.cpp:337] Iteration 51500, Testing net (#0)
I1107 23:10:45.952642  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:11:13.949648  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0586719
I1107 23:11:13.949677  3455 solver.cpp:404]     Test net output #1: loss = 3.85972 (* 1 = 3.85972 loss)
I1107 23:11:14.087716  3455 solver.cpp:228] Iteration 51500, loss = 3.86276
I1107 23:11:14.087749  3455 solver.cpp:244]     Train net output #0: loss = 3.86276 (* 1 = 3.86276 loss)
I1107 23:11:14.087756  3455 sgd_solver.cpp:106] Iteration 51500, lr = 0
I1107 23:15:26.886901  3455 solver.cpp:337] Iteration 52000, Testing net (#0)
I1107 23:15:26.886966  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:15:54.878149  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0602344
I1107 23:15:54.878180  3455 solver.cpp:404]     Test net output #1: loss = 3.85729 (* 1 = 3.85729 loss)
I1107 23:15:55.017022  3455 solver.cpp:228] Iteration 52000, loss = 3.85014
I1107 23:15:55.017052  3455 solver.cpp:244]     Train net output #0: loss = 3.85014 (* 1 = 3.85014 loss)
I1107 23:15:55.017058  3455 sgd_solver.cpp:106] Iteration 52000, lr = 0
I1107 23:20:07.829713  3455 solver.cpp:337] Iteration 52500, Testing net (#0)
I1107 23:20:07.829777  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:20:35.831149  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1107 23:20:35.831177  3455 solver.cpp:404]     Test net output #1: loss = 3.87704 (* 1 = 3.87704 loss)
I1107 23:20:35.969058  3455 solver.cpp:228] Iteration 52500, loss = 3.90592
I1107 23:20:35.969086  3455 solver.cpp:244]     Train net output #0: loss = 3.90592 (* 1 = 3.90592 loss)
I1107 23:20:35.969094  3455 sgd_solver.cpp:106] Iteration 52500, lr = 0
I1107 23:24:48.762681  3455 solver.cpp:337] Iteration 53000, Testing net (#0)
I1107 23:24:48.762753  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:25:16.737468  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607813
I1107 23:25:16.737498  3455 solver.cpp:404]     Test net output #1: loss = 3.87058 (* 1 = 3.87058 loss)
I1107 23:25:16.875375  3455 solver.cpp:228] Iteration 53000, loss = 3.89465
I1107 23:25:16.875406  3455 solver.cpp:244]     Train net output #0: loss = 3.89465 (* 1 = 3.89465 loss)
I1107 23:25:16.875414  3455 sgd_solver.cpp:106] Iteration 53000, lr = 0
I1107 23:29:29.721561  3455 solver.cpp:337] Iteration 53500, Testing net (#0)
I1107 23:29:29.743736  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:29:57.711658  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617969
I1107 23:29:57.711689  3455 solver.cpp:404]     Test net output #1: loss = 3.8588 (* 1 = 3.8588 loss)
I1107 23:29:57.850509  3455 solver.cpp:228] Iteration 53500, loss = 3.84056
I1107 23:29:57.850541  3455 solver.cpp:244]     Train net output #0: loss = 3.84056 (* 1 = 3.84056 loss)
I1107 23:29:57.850548  3455 sgd_solver.cpp:106] Iteration 53500, lr = 0
I1107 23:34:10.652070  3455 solver.cpp:337] Iteration 54000, Testing net (#0)
I1107 23:34:10.652137  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:34:38.633613  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0611719
I1107 23:34:38.633641  3455 solver.cpp:404]     Test net output #1: loss = 3.8691 (* 1 = 3.8691 loss)
I1107 23:34:38.772083  3455 solver.cpp:228] Iteration 54000, loss = 3.77499
I1107 23:34:38.772111  3455 solver.cpp:244]     Train net output #0: loss = 3.77499 (* 1 = 3.77499 loss)
I1107 23:34:38.772119  3455 sgd_solver.cpp:106] Iteration 54000, lr = 0
I1107 23:38:51.525418  3455 solver.cpp:337] Iteration 54500, Testing net (#0)
I1107 23:38:51.525466  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:39:19.514374  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0592187
I1107 23:39:19.514405  3455 solver.cpp:404]     Test net output #1: loss = 3.85941 (* 1 = 3.85941 loss)
I1107 23:39:19.652511  3455 solver.cpp:228] Iteration 54500, loss = 3.92657
I1107 23:39:19.652546  3455 solver.cpp:244]     Train net output #0: loss = 3.92657 (* 1 = 3.92657 loss)
I1107 23:39:19.652556  3455 sgd_solver.cpp:106] Iteration 54500, lr = 0
I1107 23:43:32.433034  3455 solver.cpp:337] Iteration 55000, Testing net (#0)
I1107 23:43:32.433094  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:44:00.413983  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1107 23:44:00.414016  3455 solver.cpp:404]     Test net output #1: loss = 3.85901 (* 1 = 3.85901 loss)
I1107 23:44:00.552119  3455 solver.cpp:228] Iteration 55000, loss = 3.85238
I1107 23:44:00.552150  3455 solver.cpp:244]     Train net output #0: loss = 3.85238 (* 1 = 3.85238 loss)
I1107 23:44:00.552157  3455 sgd_solver.cpp:106] Iteration 55000, lr = 0
I1107 23:48:13.299805  3455 solver.cpp:337] Iteration 55500, Testing net (#0)
I1107 23:48:13.299862  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:48:41.275426  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1107 23:48:41.275457  3455 solver.cpp:404]     Test net output #1: loss = 3.86744 (* 1 = 3.86744 loss)
I1107 23:48:41.413530  3455 solver.cpp:228] Iteration 55500, loss = 3.90265
I1107 23:48:41.413563  3455 solver.cpp:244]     Train net output #0: loss = 3.90265 (* 1 = 3.90265 loss)
I1107 23:48:41.413569  3455 sgd_solver.cpp:106] Iteration 55500, lr = 0
I1107 23:52:54.154464  3455 solver.cpp:337] Iteration 56000, Testing net (#0)
I1107 23:52:54.154537  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:53:22.145758  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0609375
I1107 23:53:22.145787  3455 solver.cpp:404]     Test net output #1: loss = 3.85769 (* 1 = 3.85769 loss)
I1107 23:53:22.283610  3455 solver.cpp:228] Iteration 56000, loss = 3.93209
I1107 23:53:22.283639  3455 solver.cpp:244]     Train net output #0: loss = 3.93209 (* 1 = 3.93209 loss)
I1107 23:53:22.283645  3455 sgd_solver.cpp:106] Iteration 56000, lr = 0
I1107 23:57:35.046346  3455 solver.cpp:337] Iteration 56500, Testing net (#0)
I1107 23:57:35.046404  3455 net.cpp:693] Ignoring source layer train_data
I1107 23:58:03.027572  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617969
I1107 23:58:03.027603  3455 solver.cpp:404]     Test net output #1: loss = 3.87809 (* 1 = 3.87809 loss)
I1107 23:58:03.166110  3455 solver.cpp:228] Iteration 56500, loss = 3.91029
I1107 23:58:03.166139  3455 solver.cpp:244]     Train net output #0: loss = 3.91029 (* 1 = 3.91029 loss)
I1107 23:58:03.166146  3455 sgd_solver.cpp:106] Iteration 56500, lr = 0
I1108 00:02:15.957022  3455 solver.cpp:337] Iteration 57000, Testing net (#0)
I1108 00:02:15.957089  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:02:43.940322  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0571875
I1108 00:02:43.940351  3455 solver.cpp:404]     Test net output #1: loss = 3.87645 (* 1 = 3.87645 loss)
I1108 00:02:44.078919  3455 solver.cpp:228] Iteration 57000, loss = 3.73876
I1108 00:02:44.078948  3455 solver.cpp:244]     Train net output #0: loss = 3.73876 (* 1 = 3.73876 loss)
I1108 00:02:44.078956  3455 sgd_solver.cpp:106] Iteration 57000, lr = 0
I1108 00:06:56.862215  3455 solver.cpp:337] Iteration 57500, Testing net (#0)
I1108 00:06:56.862275  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:07:24.843027  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 00:07:24.843055  3455 solver.cpp:404]     Test net output #1: loss = 3.8849 (* 1 = 3.8849 loss)
I1108 00:07:24.981376  3455 solver.cpp:228] Iteration 57500, loss = 3.83914
I1108 00:07:24.981405  3455 solver.cpp:244]     Train net output #0: loss = 3.83914 (* 1 = 3.83914 loss)
I1108 00:07:24.981412  3455 sgd_solver.cpp:106] Iteration 57500, lr = 0
I1108 00:11:37.750825  3455 solver.cpp:337] Iteration 58000, Testing net (#0)
I1108 00:11:37.750885  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:12:05.722739  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0592187
I1108 00:12:05.722772  3455 solver.cpp:404]     Test net output #1: loss = 3.86914 (* 1 = 3.86914 loss)
I1108 00:12:05.863971  3455 solver.cpp:228] Iteration 58000, loss = 3.8738
I1108 00:12:05.864001  3455 solver.cpp:244]     Train net output #0: loss = 3.8738 (* 1 = 3.8738 loss)
I1108 00:12:05.864008  3455 sgd_solver.cpp:106] Iteration 58000, lr = 0
I1108 00:16:18.650723  3455 solver.cpp:337] Iteration 58500, Testing net (#0)
I1108 00:16:18.650780  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:16:46.632866  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0616406
I1108 00:16:46.632897  3455 solver.cpp:404]     Test net output #1: loss = 3.89581 (* 1 = 3.89581 loss)
I1108 00:16:46.774183  3455 solver.cpp:228] Iteration 58500, loss = 3.85037
I1108 00:16:46.774214  3455 solver.cpp:244]     Train net output #0: loss = 3.85037 (* 1 = 3.85037 loss)
I1108 00:16:46.774221  3455 sgd_solver.cpp:106] Iteration 58500, lr = 0
I1108 00:20:59.588423  3455 solver.cpp:337] Iteration 59000, Testing net (#0)
I1108 00:20:59.588488  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:21:27.556448  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0601562
I1108 00:21:27.556478  3455 solver.cpp:404]     Test net output #1: loss = 3.87066 (* 1 = 3.87066 loss)
I1108 00:21:27.694952  3455 solver.cpp:228] Iteration 59000, loss = 3.88757
I1108 00:21:27.694984  3455 solver.cpp:244]     Train net output #0: loss = 3.88757 (* 1 = 3.88757 loss)
I1108 00:21:27.694993  3455 sgd_solver.cpp:106] Iteration 59000, lr = 0
I1108 00:25:40.493358  3455 solver.cpp:337] Iteration 59500, Testing net (#0)
I1108 00:25:40.493415  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:26:08.473269  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0617188
I1108 00:26:08.473302  3455 solver.cpp:404]     Test net output #1: loss = 3.86409 (* 1 = 3.86409 loss)
I1108 00:26:08.611337  3455 solver.cpp:228] Iteration 59500, loss = 3.79424
I1108 00:26:08.611371  3455 solver.cpp:244]     Train net output #0: loss = 3.79424 (* 1 = 3.79424 loss)
I1108 00:26:08.611377  3455 sgd_solver.cpp:106] Iteration 59500, lr = 0
I1108 00:30:21.442819  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_60000.caffemodel
I1108 00:30:48.923876  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_60000.solverstate
I1108 00:30:51.304448  3455 solver.cpp:337] Iteration 60000, Testing net (#0)
I1108 00:30:51.304502  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:31:18.919384  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0594531
I1108 00:31:18.919468  3455 solver.cpp:404]     Test net output #1: loss = 3.89463 (* 1 = 3.89463 loss)
I1108 00:31:19.057938  3455 solver.cpp:228] Iteration 60000, loss = 3.80391
I1108 00:31:19.057978  3455 solver.cpp:244]     Train net output #0: loss = 3.80391 (* 1 = 3.80391 loss)
I1108 00:31:19.057991  3455 sgd_solver.cpp:106] Iteration 60000, lr = 0
I1108 00:35:31.802958  3455 solver.cpp:337] Iteration 60500, Testing net (#0)
I1108 00:35:31.803021  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:35:59.769356  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0582813
I1108 00:35:59.769393  3455 solver.cpp:404]     Test net output #1: loss = 3.90207 (* 1 = 3.90207 loss)
I1108 00:35:59.911351  3455 solver.cpp:228] Iteration 60500, loss = 3.84177
I1108 00:35:59.911383  3455 solver.cpp:244]     Train net output #0: loss = 3.84177 (* 1 = 3.84177 loss)
I1108 00:35:59.911391  3455 sgd_solver.cpp:106] Iteration 60500, lr = 0
I1108 00:40:12.645373  3455 solver.cpp:337] Iteration 61000, Testing net (#0)
I1108 00:40:12.645436  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:40:40.599617  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0629688
I1108 00:40:40.599647  3455 solver.cpp:404]     Test net output #1: loss = 3.87258 (* 1 = 3.87258 loss)
I1108 00:40:40.737732  3455 solver.cpp:228] Iteration 61000, loss = 3.80834
I1108 00:40:40.737764  3455 solver.cpp:244]     Train net output #0: loss = 3.80834 (* 1 = 3.80834 loss)
I1108 00:40:40.737771  3455 sgd_solver.cpp:106] Iteration 61000, lr = 0
I1108 00:44:53.463465  3455 solver.cpp:337] Iteration 61500, Testing net (#0)
I1108 00:44:53.463539  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:45:21.404999  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0601562
I1108 00:45:21.405030  3455 solver.cpp:404]     Test net output #1: loss = 3.85702 (* 1 = 3.85702 loss)
I1108 00:45:21.542923  3455 solver.cpp:228] Iteration 61500, loss = 3.92193
I1108 00:45:21.542956  3455 solver.cpp:244]     Train net output #0: loss = 3.92193 (* 1 = 3.92193 loss)
I1108 00:45:21.542964  3455 sgd_solver.cpp:106] Iteration 61500, lr = 0
I1108 00:49:34.272997  3455 solver.cpp:337] Iteration 62000, Testing net (#0)
I1108 00:49:34.273058  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:50:02.252564  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0615625
I1108 00:50:02.252593  3455 solver.cpp:404]     Test net output #1: loss = 3.86673 (* 1 = 3.86673 loss)
I1108 00:50:02.390770  3455 solver.cpp:228] Iteration 62000, loss = 3.76509
I1108 00:50:02.390800  3455 solver.cpp:244]     Train net output #0: loss = 3.76509 (* 1 = 3.76509 loss)
I1108 00:50:02.390807  3455 sgd_solver.cpp:106] Iteration 62000, lr = 0
I1108 00:54:15.159071  3455 solver.cpp:337] Iteration 62500, Testing net (#0)
I1108 00:54:15.159133  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:54:43.135315  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0586719
I1108 00:54:43.135344  3455 solver.cpp:404]     Test net output #1: loss = 3.87523 (* 1 = 3.87523 loss)
I1108 00:54:43.273072  3455 solver.cpp:228] Iteration 62500, loss = 3.89309
I1108 00:54:43.273102  3455 solver.cpp:244]     Train net output #0: loss = 3.89309 (* 1 = 3.89309 loss)
I1108 00:54:43.273108  3455 sgd_solver.cpp:106] Iteration 62500, lr = 0
I1108 00:58:55.994143  3455 solver.cpp:337] Iteration 63000, Testing net (#0)
I1108 00:58:55.994217  3455 net.cpp:693] Ignoring source layer train_data
I1108 00:59:23.974853  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0603906
I1108 00:59:23.974884  3455 solver.cpp:404]     Test net output #1: loss = 3.85533 (* 1 = 3.85533 loss)
I1108 00:59:24.112977  3455 solver.cpp:228] Iteration 63000, loss = 3.7622
I1108 00:59:24.113005  3455 solver.cpp:244]     Train net output #0: loss = 3.7622 (* 1 = 3.7622 loss)
I1108 00:59:24.113013  3455 sgd_solver.cpp:106] Iteration 63000, lr = 0
I1108 01:03:36.855938  3455 solver.cpp:337] Iteration 63500, Testing net (#0)
I1108 01:03:36.875320  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:04:04.849233  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0578906
I1108 01:04:04.849262  3455 solver.cpp:404]     Test net output #1: loss = 3.87957 (* 1 = 3.87957 loss)
I1108 01:04:04.987527  3455 solver.cpp:228] Iteration 63500, loss = 3.85728
I1108 01:04:04.987557  3455 solver.cpp:244]     Train net output #0: loss = 3.85728 (* 1 = 3.85728 loss)
I1108 01:04:04.987565  3455 sgd_solver.cpp:106] Iteration 63500, lr = 0
I1108 01:08:17.750571  3455 solver.cpp:337] Iteration 64000, Testing net (#0)
I1108 01:08:17.750629  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:08:45.719691  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0621875
I1108 01:08:45.719722  3455 solver.cpp:404]     Test net output #1: loss = 3.87831 (* 1 = 3.87831 loss)
I1108 01:08:45.857710  3455 solver.cpp:228] Iteration 64000, loss = 3.79091
I1108 01:08:45.857745  3455 solver.cpp:244]     Train net output #0: loss = 3.79091 (* 1 = 3.79091 loss)
I1108 01:08:45.857753  3455 sgd_solver.cpp:106] Iteration 64000, lr = 0
I1108 01:12:58.607692  3455 solver.cpp:337] Iteration 64500, Testing net (#0)
I1108 01:12:58.607751  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:13:26.600111  3455 solver.cpp:404]     Test net output #0: accuracy = 0.059375
I1108 01:13:26.600142  3455 solver.cpp:404]     Test net output #1: loss = 3.85715 (* 1 = 3.85715 loss)
I1108 01:13:26.741547  3455 solver.cpp:228] Iteration 64500, loss = 3.82522
I1108 01:13:26.741577  3455 solver.cpp:244]     Train net output #0: loss = 3.82522 (* 1 = 3.82522 loss)
I1108 01:13:26.741585  3455 sgd_solver.cpp:106] Iteration 64500, lr = 0
I1108 01:17:39.526141  3455 solver.cpp:337] Iteration 65000, Testing net (#0)
I1108 01:17:39.526204  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:18:07.527487  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0620313
I1108 01:18:07.527513  3455 solver.cpp:404]     Test net output #1: loss = 3.8693 (* 1 = 3.8693 loss)
I1108 01:18:07.666064  3455 solver.cpp:228] Iteration 65000, loss = 3.83135
I1108 01:18:07.666096  3455 solver.cpp:244]     Train net output #0: loss = 3.83135 (* 1 = 3.83135 loss)
I1108 01:18:07.666105  3455 sgd_solver.cpp:106] Iteration 65000, lr = 0
I1108 01:22:20.399873  3455 solver.cpp:337] Iteration 65500, Testing net (#0)
I1108 01:22:20.399930  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:22:48.389987  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1108 01:22:48.390022  3455 solver.cpp:404]     Test net output #1: loss = 3.87694 (* 1 = 3.87694 loss)
I1108 01:22:48.528090  3455 solver.cpp:228] Iteration 65500, loss = 5.1341
I1108 01:22:48.528122  3455 solver.cpp:244]     Train net output #0: loss = 5.1341 (* 1 = 5.1341 loss)
I1108 01:22:48.528129  3455 sgd_solver.cpp:106] Iteration 65500, lr = 0
I1108 01:27:01.308043  3455 solver.cpp:337] Iteration 66000, Testing net (#0)
I1108 01:27:01.308096  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:27:29.293985  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0582031
I1108 01:27:29.294018  3455 solver.cpp:404]     Test net output #1: loss = 3.87595 (* 1 = 3.87595 loss)
I1108 01:27:29.432095  3455 solver.cpp:228] Iteration 66000, loss = 3.90966
I1108 01:27:29.432126  3455 solver.cpp:244]     Train net output #0: loss = 3.90966 (* 1 = 3.90966 loss)
I1108 01:27:29.432133  3455 sgd_solver.cpp:106] Iteration 66000, lr = 0
I1108 01:31:42.217895  3455 solver.cpp:337] Iteration 66500, Testing net (#0)
I1108 01:31:42.217965  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:32:10.209266  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0639063
I1108 01:32:10.209298  3455 solver.cpp:404]     Test net output #1: loss = 3.88286 (* 1 = 3.88286 loss)
I1108 01:32:10.347407  3455 solver.cpp:228] Iteration 66500, loss = 3.90219
I1108 01:32:10.347440  3455 solver.cpp:244]     Train net output #0: loss = 3.90219 (* 1 = 3.90219 loss)
I1108 01:32:10.347446  3455 sgd_solver.cpp:106] Iteration 66500, lr = 0
I1108 01:36:23.083863  3455 solver.cpp:337] Iteration 67000, Testing net (#0)
I1108 01:36:23.083930  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:36:51.074126  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0600781
I1108 01:36:51.074153  3455 solver.cpp:404]     Test net output #1: loss = 3.86624 (* 1 = 3.86624 loss)
I1108 01:36:51.211874  3455 solver.cpp:228] Iteration 67000, loss = 3.77699
I1108 01:36:51.211902  3455 solver.cpp:244]     Train net output #0: loss = 3.77699 (* 1 = 3.77699 loss)
I1108 01:36:51.211908  3455 sgd_solver.cpp:106] Iteration 67000, lr = 0
I1108 01:41:03.976498  3455 solver.cpp:337] Iteration 67500, Testing net (#0)
I1108 01:41:03.976557  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:41:31.980125  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0611719
I1108 01:41:31.980154  3455 solver.cpp:404]     Test net output #1: loss = 3.85342 (* 1 = 3.85342 loss)
I1108 01:41:32.118041  3455 solver.cpp:228] Iteration 67500, loss = 3.89429
I1108 01:41:32.118070  3455 solver.cpp:244]     Train net output #0: loss = 3.89429 (* 1 = 3.89429 loss)
I1108 01:41:32.118077  3455 sgd_solver.cpp:106] Iteration 67500, lr = 0
I1108 01:45:44.868932  3455 solver.cpp:337] Iteration 68000, Testing net (#0)
I1108 01:45:44.868993  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:46:12.877646  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585156
I1108 01:46:12.877673  3455 solver.cpp:404]     Test net output #1: loss = 3.86837 (* 1 = 3.86837 loss)
I1108 01:46:13.015689  3455 solver.cpp:228] Iteration 68000, loss = 3.85645
I1108 01:46:13.015718  3455 solver.cpp:244]     Train net output #0: loss = 3.85645 (* 1 = 3.85645 loss)
I1108 01:46:13.015727  3455 sgd_solver.cpp:106] Iteration 68000, lr = 0
I1108 01:50:25.773932  3455 solver.cpp:337] Iteration 68500, Testing net (#0)
I1108 01:50:25.773993  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:50:53.775019  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1108 01:50:53.775046  3455 solver.cpp:404]     Test net output #1: loss = 3.86987 (* 1 = 3.86987 loss)
I1108 01:50:53.913018  3455 solver.cpp:228] Iteration 68500, loss = 3.86636
I1108 01:50:53.913046  3455 solver.cpp:244]     Train net output #0: loss = 3.86636 (* 1 = 3.86636 loss)
I1108 01:50:53.913053  3455 sgd_solver.cpp:106] Iteration 68500, lr = 0
I1108 01:55:06.608577  3455 solver.cpp:337] Iteration 69000, Testing net (#0)
I1108 01:55:06.608641  3455 net.cpp:693] Ignoring source layer train_data
I1108 01:55:34.613379  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0583594
I1108 01:55:34.613407  3455 solver.cpp:404]     Test net output #1: loss = 3.86559 (* 1 = 3.86559 loss)
I1108 01:55:34.751714  3455 solver.cpp:228] Iteration 69000, loss = 3.85439
I1108 01:55:34.751746  3455 solver.cpp:244]     Train net output #0: loss = 3.85439 (* 1 = 3.85439 loss)
I1108 01:55:34.751754  3455 sgd_solver.cpp:106] Iteration 69000, lr = 0
I1108 01:59:47.504148  3455 solver.cpp:337] Iteration 69500, Testing net (#0)
I1108 01:59:47.504209  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:00:15.495378  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0624219
I1108 02:00:15.495405  3455 solver.cpp:404]     Test net output #1: loss = 3.86975 (* 1 = 3.86975 loss)
I1108 02:00:15.633651  3455 solver.cpp:228] Iteration 69500, loss = 3.86581
I1108 02:00:15.633682  3455 solver.cpp:244]     Train net output #0: loss = 3.86581 (* 1 = 3.86581 loss)
I1108 02:00:15.633689  3455 sgd_solver.cpp:106] Iteration 69500, lr = 0
I1108 02:04:28.367143  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_70000.caffemodel
I1108 02:05:05.454640  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_70000.solverstate
I1108 02:05:07.738809  3455 solver.cpp:337] Iteration 70000, Testing net (#0)
I1108 02:05:07.738876  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:05:35.316064  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0575781
I1108 02:05:35.316093  3455 solver.cpp:404]     Test net output #1: loss = 3.89844 (* 1 = 3.89844 loss)
I1108 02:05:35.454242  3455 solver.cpp:228] Iteration 70000, loss = 3.80209
I1108 02:05:35.454274  3455 solver.cpp:244]     Train net output #0: loss = 3.80209 (* 1 = 3.80209 loss)
I1108 02:05:35.454282  3455 sgd_solver.cpp:106] Iteration 70000, lr = 0
I1108 02:09:48.213783  3455 solver.cpp:337] Iteration 70500, Testing net (#0)
I1108 02:09:48.213837  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:10:16.159760  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0639063
I1108 02:10:16.159786  3455 solver.cpp:404]     Test net output #1: loss = 3.86783 (* 1 = 3.86783 loss)
I1108 02:10:16.297696  3455 solver.cpp:228] Iteration 70500, loss = 3.78758
I1108 02:10:16.297725  3455 solver.cpp:244]     Train net output #0: loss = 3.78758 (* 1 = 3.78758 loss)
I1108 02:10:16.297731  3455 sgd_solver.cpp:106] Iteration 70500, lr = 0
I1108 02:14:29.016367  3455 solver.cpp:337] Iteration 71000, Testing net (#0)
I1108 02:14:29.016440  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:14:56.971441  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1108 02:14:56.971465  3455 solver.cpp:404]     Test net output #1: loss = 3.87547 (* 1 = 3.87547 loss)
I1108 02:14:57.109558  3455 solver.cpp:228] Iteration 71000, loss = 3.82637
I1108 02:14:57.109588  3455 solver.cpp:244]     Train net output #0: loss = 3.82637 (* 1 = 3.82637 loss)
I1108 02:14:57.218601  3455 sgd_solver.cpp:106] Iteration 71000, lr = 0
I1108 02:19:09.864472  3455 solver.cpp:337] Iteration 71500, Testing net (#0)
I1108 02:19:09.864552  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:19:37.843061  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0583594
I1108 02:19:37.843096  3455 solver.cpp:404]     Test net output #1: loss = 3.86989 (* 1 = 3.86989 loss)
I1108 02:19:37.981139  3455 solver.cpp:228] Iteration 71500, loss = 3.89758
I1108 02:19:37.981171  3455 solver.cpp:244]     Train net output #0: loss = 3.89758 (* 1 = 3.89758 loss)
I1108 02:19:37.981179  3455 sgd_solver.cpp:106] Iteration 71500, lr = 0
I1108 02:23:50.686697  3455 solver.cpp:337] Iteration 72000, Testing net (#0)
I1108 02:23:50.686755  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:24:18.682322  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607813
I1108 02:24:18.682351  3455 solver.cpp:404]     Test net output #1: loss = 3.85239 (* 1 = 3.85239 loss)
I1108 02:24:18.820858  3455 solver.cpp:228] Iteration 72000, loss = 3.8875
I1108 02:24:18.820891  3455 solver.cpp:244]     Train net output #0: loss = 3.8875 (* 1 = 3.8875 loss)
I1108 02:24:18.820899  3455 sgd_solver.cpp:106] Iteration 72000, lr = 0
I1108 02:28:31.493157  3455 solver.cpp:337] Iteration 72500, Testing net (#0)
I1108 02:28:31.493216  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:28:59.476706  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06125
I1108 02:28:59.476735  3455 solver.cpp:404]     Test net output #1: loss = 3.87238 (* 1 = 3.87238 loss)
I1108 02:28:59.615717  3455 solver.cpp:228] Iteration 72500, loss = 3.9387
I1108 02:28:59.615748  3455 solver.cpp:244]     Train net output #0: loss = 3.9387 (* 1 = 3.9387 loss)
I1108 02:28:59.615756  3455 sgd_solver.cpp:106] Iteration 72500, lr = 0
I1108 02:33:12.342195  3455 solver.cpp:337] Iteration 73000, Testing net (#0)
I1108 02:33:12.342267  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:33:40.317591  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1108 02:33:40.317621  3455 solver.cpp:404]     Test net output #1: loss = 3.86167 (* 1 = 3.86167 loss)
I1108 02:33:40.455857  3455 solver.cpp:228] Iteration 73000, loss = 3.91145
I1108 02:33:40.455888  3455 solver.cpp:244]     Train net output #0: loss = 3.91145 (* 1 = 3.91145 loss)
I1108 02:33:40.455893  3455 sgd_solver.cpp:106] Iteration 73000, lr = 0
I1108 02:37:53.194669  3455 solver.cpp:337] Iteration 73500, Testing net (#0)
I1108 02:37:53.215055  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:38:21.179208  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1108 02:38:21.179241  3455 solver.cpp:404]     Test net output #1: loss = 3.87864 (* 1 = 3.87864 loss)
I1108 02:38:21.317503  3455 solver.cpp:228] Iteration 73500, loss = 3.87127
I1108 02:38:21.317541  3455 solver.cpp:244]     Train net output #0: loss = 3.87127 (* 1 = 3.87127 loss)
I1108 02:38:21.317550  3455 sgd_solver.cpp:106] Iteration 73500, lr = 0
I1108 02:42:34.011857  3455 solver.cpp:337] Iteration 74000, Testing net (#0)
I1108 02:42:34.031213  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:43:01.987149  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596094
I1108 02:43:01.987182  3455 solver.cpp:404]     Test net output #1: loss = 3.89097 (* 1 = 3.89097 loss)
I1108 02:43:02.125318  3455 solver.cpp:228] Iteration 74000, loss = 3.8518
I1108 02:43:02.125350  3455 solver.cpp:244]     Train net output #0: loss = 3.8518 (* 1 = 3.8518 loss)
I1108 02:43:02.125357  3455 sgd_solver.cpp:106] Iteration 74000, lr = 0
I1108 02:47:14.800690  3455 solver.cpp:337] Iteration 74500, Testing net (#0)
I1108 02:47:14.800750  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:47:42.775280  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1108 02:47:42.775311  3455 solver.cpp:404]     Test net output #1: loss = 3.8565 (* 1 = 3.8565 loss)
I1108 02:47:42.913895  3455 solver.cpp:228] Iteration 74500, loss = 3.82687
I1108 02:47:42.913924  3455 solver.cpp:244]     Train net output #0: loss = 3.82687 (* 1 = 3.82687 loss)
I1108 02:47:42.913931  3455 sgd_solver.cpp:106] Iteration 74500, lr = 0
I1108 02:51:55.671743  3455 solver.cpp:337] Iteration 75000, Testing net (#0)
I1108 02:51:55.671803  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:52:23.645421  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614844
I1108 02:52:23.645452  3455 solver.cpp:404]     Test net output #1: loss = 3.86275 (* 1 = 3.86275 loss)
I1108 02:52:23.784162  3455 solver.cpp:228] Iteration 75000, loss = 3.772
I1108 02:52:23.784195  3455 solver.cpp:244]     Train net output #0: loss = 3.772 (* 1 = 3.772 loss)
I1108 02:52:23.784204  3455 sgd_solver.cpp:106] Iteration 75000, lr = 0
I1108 02:56:36.504196  3455 solver.cpp:337] Iteration 75500, Testing net (#0)
I1108 02:56:36.504256  3455 net.cpp:693] Ignoring source layer train_data
I1108 02:57:04.482100  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0578906
I1108 02:57:04.482130  3455 solver.cpp:404]     Test net output #1: loss = 3.88583 (* 1 = 3.88583 loss)
I1108 02:57:04.620317  3455 solver.cpp:228] Iteration 75500, loss = 3.81988
I1108 02:57:04.620349  3455 solver.cpp:244]     Train net output #0: loss = 3.81988 (* 1 = 3.81988 loss)
I1108 02:57:04.620357  3455 sgd_solver.cpp:106] Iteration 75500, lr = 0
I1108 03:01:17.332608  3455 solver.cpp:337] Iteration 76000, Testing net (#0)
I1108 03:01:17.332689  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:01:45.286531  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0628906
I1108 03:01:45.286559  3455 solver.cpp:404]     Test net output #1: loss = 3.87566 (* 1 = 3.87566 loss)
I1108 03:01:45.424708  3455 solver.cpp:228] Iteration 76000, loss = 3.93565
I1108 03:01:45.424741  3455 solver.cpp:244]     Train net output #0: loss = 3.93565 (* 1 = 3.93565 loss)
I1108 03:01:45.424751  3455 sgd_solver.cpp:106] Iteration 76000, lr = 0
I1108 03:05:58.121594  3455 solver.cpp:337] Iteration 76500, Testing net (#0)
I1108 03:05:58.121682  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:06:26.070142  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1108 03:06:26.070174  3455 solver.cpp:404]     Test net output #1: loss = 3.88001 (* 1 = 3.88001 loss)
I1108 03:06:26.207870  3455 solver.cpp:228] Iteration 76500, loss = 3.81676
I1108 03:06:26.207903  3455 solver.cpp:244]     Train net output #0: loss = 3.81676 (* 1 = 3.81676 loss)
I1108 03:06:26.207914  3455 sgd_solver.cpp:106] Iteration 76500, lr = 0
I1108 03:10:38.894636  3455 solver.cpp:337] Iteration 77000, Testing net (#0)
I1108 03:10:38.894711  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:11:06.839139  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1108 03:11:06.839169  3455 solver.cpp:404]     Test net output #1: loss = 3.867 (* 1 = 3.867 loss)
I1108 03:11:06.975894  3455 solver.cpp:228] Iteration 77000, loss = 3.81422
I1108 03:11:06.975925  3455 solver.cpp:244]     Train net output #0: loss = 3.81422 (* 1 = 3.81422 loss)
I1108 03:11:06.975935  3455 sgd_solver.cpp:106] Iteration 77000, lr = 0
I1108 03:15:19.697964  3455 solver.cpp:337] Iteration 77500, Testing net (#0)
I1108 03:15:19.698029  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:15:47.640207  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 03:15:47.640239  3455 solver.cpp:404]     Test net output #1: loss = 3.87095 (* 1 = 3.87095 loss)
I1108 03:15:47.778609  3455 solver.cpp:228] Iteration 77500, loss = 3.67617
I1108 03:15:47.778642  3455 solver.cpp:244]     Train net output #0: loss = 3.67617 (* 1 = 3.67617 loss)
I1108 03:15:47.778653  3455 sgd_solver.cpp:106] Iteration 77500, lr = 0
I1108 03:20:00.527535  3455 solver.cpp:337] Iteration 78000, Testing net (#0)
I1108 03:20:00.527601  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:20:28.482779  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1108 03:20:28.482810  3455 solver.cpp:404]     Test net output #1: loss = 3.84643 (* 1 = 3.84643 loss)
I1108 03:20:28.620918  3455 solver.cpp:228] Iteration 78000, loss = 3.91327
I1108 03:20:28.620951  3455 solver.cpp:244]     Train net output #0: loss = 3.91327 (* 1 = 3.91327 loss)
I1108 03:20:28.620966  3455 sgd_solver.cpp:106] Iteration 78000, lr = 0
I1108 03:24:41.315345  3455 solver.cpp:337] Iteration 78500, Testing net (#0)
I1108 03:24:41.315409  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:25:09.268766  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614063
I1108 03:25:09.268793  3455 solver.cpp:404]     Test net output #1: loss = 3.86722 (* 1 = 3.86722 loss)
I1108 03:25:09.407220  3455 solver.cpp:228] Iteration 78500, loss = 3.85553
I1108 03:25:09.407253  3455 solver.cpp:244]     Train net output #0: loss = 3.85553 (* 1 = 3.85553 loss)
I1108 03:25:09.407263  3455 sgd_solver.cpp:106] Iteration 78500, lr = 0
I1108 03:29:22.116663  3455 solver.cpp:337] Iteration 79000, Testing net (#0)
I1108 03:29:22.116720  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:29:50.071285  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1108 03:29:50.071315  3455 solver.cpp:404]     Test net output #1: loss = 3.86701 (* 1 = 3.86701 loss)
I1108 03:29:50.209624  3455 solver.cpp:228] Iteration 79000, loss = 3.80022
I1108 03:29:50.209655  3455 solver.cpp:244]     Train net output #0: loss = 3.80022 (* 1 = 3.80022 loss)
I1108 03:29:50.209663  3455 sgd_solver.cpp:106] Iteration 79000, lr = 0
I1108 03:34:02.972390  3455 solver.cpp:337] Iteration 79500, Testing net (#0)
I1108 03:34:02.972447  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:34:30.921968  3455 solver.cpp:404]     Test net output #0: accuracy = 0.05875
I1108 03:34:30.921998  3455 solver.cpp:404]     Test net output #1: loss = 3.86649 (* 1 = 3.86649 loss)
I1108 03:34:31.059784  3455 solver.cpp:228] Iteration 79500, loss = 3.85369
I1108 03:34:31.059819  3455 solver.cpp:244]     Train net output #0: loss = 3.85369 (* 1 = 3.85369 loss)
I1108 03:34:31.059829  3455 sgd_solver.cpp:106] Iteration 79500, lr = 0
I1108 03:38:43.813889  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_80000.caffemodel
I1108 03:39:26.859904  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_80000.solverstate
I1108 03:39:29.099156  3455 solver.cpp:337] Iteration 80000, Testing net (#0)
I1108 03:39:29.099203  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:39:56.714395  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 03:39:56.714427  3455 solver.cpp:404]     Test net output #1: loss = 3.86119 (* 1 = 3.86119 loss)
I1108 03:39:56.855217  3455 solver.cpp:228] Iteration 80000, loss = 3.91682
I1108 03:39:56.855247  3455 solver.cpp:244]     Train net output #0: loss = 3.91682 (* 1 = 3.91682 loss)
I1108 03:39:56.855253  3455 sgd_solver.cpp:106] Iteration 80000, lr = 0
I1108 03:44:09.615492  3455 solver.cpp:337] Iteration 80500, Testing net (#0)
I1108 03:44:09.615562  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:44:37.587410  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610938
I1108 03:44:37.587441  3455 solver.cpp:404]     Test net output #1: loss = 3.88787 (* 1 = 3.88787 loss)
I1108 03:44:37.726166  3455 solver.cpp:228] Iteration 80500, loss = 3.79396
I1108 03:44:37.726197  3455 solver.cpp:244]     Train net output #0: loss = 3.79396 (* 1 = 3.79396 loss)
I1108 03:44:37.726202  3455 sgd_solver.cpp:106] Iteration 80500, lr = 0
I1108 03:48:50.476589  3455 solver.cpp:337] Iteration 81000, Testing net (#0)
I1108 03:48:50.476655  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:49:18.450317  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585156
I1108 03:49:18.450352  3455 solver.cpp:404]     Test net output #1: loss = 3.85913 (* 1 = 3.85913 loss)
I1108 03:49:18.588747  3455 solver.cpp:228] Iteration 81000, loss = 3.93334
I1108 03:49:18.588780  3455 solver.cpp:244]     Train net output #0: loss = 3.93334 (* 1 = 3.93334 loss)
I1108 03:49:18.588788  3455 sgd_solver.cpp:106] Iteration 81000, lr = 0
I1108 03:53:31.270594  3455 solver.cpp:337] Iteration 81500, Testing net (#0)
I1108 03:53:31.270660  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:53:59.230705  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0626563
I1108 03:53:59.230733  3455 solver.cpp:404]     Test net output #1: loss = 3.89494 (* 1 = 3.89494 loss)
I1108 03:53:59.369132  3455 solver.cpp:228] Iteration 81500, loss = 3.79879
I1108 03:53:59.369160  3455 solver.cpp:244]     Train net output #0: loss = 3.79879 (* 1 = 3.79879 loss)
I1108 03:53:59.369168  3455 sgd_solver.cpp:106] Iteration 81500, lr = 0
I1108 03:58:12.074458  3455 solver.cpp:337] Iteration 82000, Testing net (#0)
I1108 03:58:12.074523  3455 net.cpp:693] Ignoring source layer train_data
I1108 03:58:40.017956  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0600781
I1108 03:58:40.017992  3455 solver.cpp:404]     Test net output #1: loss = 3.85991 (* 1 = 3.85991 loss)
I1108 03:58:40.156850  3455 solver.cpp:228] Iteration 82000, loss = 3.8226
I1108 03:58:40.156886  3455 solver.cpp:244]     Train net output #0: loss = 3.8226 (* 1 = 3.8226 loss)
I1108 03:58:40.156895  3455 sgd_solver.cpp:106] Iteration 82000, lr = 0
I1108 04:02:52.833941  3455 solver.cpp:337] Iteration 82500, Testing net (#0)
I1108 04:02:52.833997  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:03:20.776799  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0589844
I1108 04:03:20.776826  3455 solver.cpp:404]     Test net output #1: loss = 3.86326 (* 1 = 3.86326 loss)
I1108 04:03:20.915035  3455 solver.cpp:228] Iteration 82500, loss = 3.79187
I1108 04:03:20.915065  3455 solver.cpp:244]     Train net output #0: loss = 3.79187 (* 1 = 3.79187 loss)
I1108 04:03:20.915071  3455 sgd_solver.cpp:106] Iteration 82500, lr = 0
I1108 04:07:33.608841  3455 solver.cpp:337] Iteration 83000, Testing net (#0)
I1108 04:07:33.608908  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:08:01.557086  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0611719
I1108 04:08:01.557114  3455 solver.cpp:404]     Test net output #1: loss = 3.87695 (* 1 = 3.87695 loss)
I1108 04:08:01.695631  3455 solver.cpp:228] Iteration 83000, loss = 3.80356
I1108 04:08:01.695663  3455 solver.cpp:244]     Train net output #0: loss = 3.80356 (* 1 = 3.80356 loss)
I1108 04:08:01.695670  3455 sgd_solver.cpp:106] Iteration 83000, lr = 0
I1108 04:12:14.427103  3455 solver.cpp:337] Iteration 83500, Testing net (#0)
I1108 04:12:14.442178  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:12:42.384263  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596875
I1108 04:12:42.384294  3455 solver.cpp:404]     Test net output #1: loss = 3.85997 (* 1 = 3.85997 loss)
I1108 04:12:42.522209  3455 solver.cpp:228] Iteration 83500, loss = 3.83569
I1108 04:12:42.522241  3455 solver.cpp:244]     Train net output #0: loss = 3.83569 (* 1 = 3.83569 loss)
I1108 04:12:42.522248  3455 sgd_solver.cpp:106] Iteration 83500, lr = 0
I1108 04:16:55.306370  3455 solver.cpp:337] Iteration 84000, Testing net (#0)
I1108 04:16:55.306414  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:17:23.272539  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1108 04:17:23.272570  3455 solver.cpp:404]     Test net output #1: loss = 3.87955 (* 1 = 3.87955 loss)
I1108 04:17:23.410611  3455 solver.cpp:228] Iteration 84000, loss = 3.8118
I1108 04:17:23.410645  3455 solver.cpp:244]     Train net output #0: loss = 3.8118 (* 1 = 3.8118 loss)
I1108 04:17:23.410652  3455 sgd_solver.cpp:106] Iteration 84000, lr = 0
I1108 04:21:36.102231  3455 solver.cpp:337] Iteration 84500, Testing net (#0)
I1108 04:21:36.102299  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:22:04.056031  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0596094
I1108 04:22:04.056059  3455 solver.cpp:404]     Test net output #1: loss = 3.8956 (* 1 = 3.8956 loss)
I1108 04:22:04.193929  3455 solver.cpp:228] Iteration 84500, loss = 3.71682
I1108 04:22:04.193958  3455 solver.cpp:244]     Train net output #0: loss = 3.71682 (* 1 = 3.71682 loss)
I1108 04:22:04.193965  3455 sgd_solver.cpp:106] Iteration 84500, lr = 0
I1108 04:26:16.907778  3455 solver.cpp:337] Iteration 85000, Testing net (#0)
I1108 04:26:16.907835  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:26:44.877857  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0595312
I1108 04:26:44.877892  3455 solver.cpp:404]     Test net output #1: loss = 3.8621 (* 1 = 3.8621 loss)
I1108 04:26:45.016571  3455 solver.cpp:228] Iteration 85000, loss = 3.8558
I1108 04:26:45.016602  3455 solver.cpp:244]     Train net output #0: loss = 3.8558 (* 1 = 3.8558 loss)
I1108 04:26:45.016608  3455 sgd_solver.cpp:106] Iteration 85000, lr = 0
I1108 04:30:57.732254  3455 solver.cpp:337] Iteration 85500, Testing net (#0)
I1108 04:30:57.732307  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:31:25.697667  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0598437
I1108 04:31:25.697695  3455 solver.cpp:404]     Test net output #1: loss = 3.87722 (* 1 = 3.87722 loss)
I1108 04:31:25.835690  3455 solver.cpp:228] Iteration 85500, loss = 3.94811
I1108 04:31:25.835717  3455 solver.cpp:244]     Train net output #0: loss = 3.94811 (* 1 = 3.94811 loss)
I1108 04:31:25.835724  3455 sgd_solver.cpp:106] Iteration 85500, lr = 0
I1108 04:35:38.617996  3455 solver.cpp:337] Iteration 86000, Testing net (#0)
I1108 04:35:38.618057  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:36:06.602643  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 04:36:06.602669  3455 solver.cpp:404]     Test net output #1: loss = 3.87278 (* 1 = 3.87278 loss)
I1108 04:36:06.740804  3455 solver.cpp:228] Iteration 86000, loss = 3.88794
I1108 04:36:06.740833  3455 solver.cpp:244]     Train net output #0: loss = 3.88794 (* 1 = 3.88794 loss)
I1108 04:36:06.740839  3455 sgd_solver.cpp:106] Iteration 86000, lr = 0
I1108 04:40:19.490203  3455 solver.cpp:337] Iteration 86500, Testing net (#0)
I1108 04:40:19.490280  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:40:47.461282  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0588281
I1108 04:40:47.461311  3455 solver.cpp:404]     Test net output #1: loss = 3.86495 (* 1 = 3.86495 loss)
I1108 04:40:47.599726  3455 solver.cpp:228] Iteration 86500, loss = 3.82653
I1108 04:40:47.599755  3455 solver.cpp:244]     Train net output #0: loss = 3.82653 (* 1 = 3.82653 loss)
I1108 04:40:47.599761  3455 sgd_solver.cpp:106] Iteration 86500, lr = 0
I1108 04:45:00.366103  3455 solver.cpp:337] Iteration 87000, Testing net (#0)
I1108 04:45:00.366147  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:45:28.329308  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0625
I1108 04:45:28.329341  3455 solver.cpp:404]     Test net output #1: loss = 3.85852 (* 1 = 3.85852 loss)
I1108 04:45:28.467499  3455 solver.cpp:228] Iteration 87000, loss = 3.84103
I1108 04:45:28.467531  3455 solver.cpp:244]     Train net output #0: loss = 3.84103 (* 1 = 3.84103 loss)
I1108 04:45:28.467540  3455 sgd_solver.cpp:106] Iteration 87000, lr = 0
I1108 04:49:41.236433  3455 solver.cpp:337] Iteration 87500, Testing net (#0)
I1108 04:49:41.236486  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:50:09.200371  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0605469
I1108 04:50:09.200403  3455 solver.cpp:404]     Test net output #1: loss = 3.87037 (* 1 = 3.87037 loss)
I1108 04:50:09.338927  3455 solver.cpp:228] Iteration 87500, loss = 3.88499
I1108 04:50:09.338959  3455 solver.cpp:244]     Train net output #0: loss = 3.88499 (* 1 = 3.88499 loss)
I1108 04:50:09.338966  3455 sgd_solver.cpp:106] Iteration 87500, lr = 0
I1108 04:54:22.041360  3455 solver.cpp:337] Iteration 88000, Testing net (#0)
I1108 04:54:22.041415  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:54:50.006855  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0585938
I1108 04:54:50.006889  3455 solver.cpp:404]     Test net output #1: loss = 3.87102 (* 1 = 3.87102 loss)
I1108 04:54:50.145326  3455 solver.cpp:228] Iteration 88000, loss = 3.86014
I1108 04:54:50.145356  3455 solver.cpp:244]     Train net output #0: loss = 3.86014 (* 1 = 3.86014 loss)
I1108 04:54:50.145368  3455 sgd_solver.cpp:106] Iteration 88000, lr = 0
I1108 04:59:02.885149  3455 solver.cpp:337] Iteration 88500, Testing net (#0)
I1108 04:59:02.885205  3455 net.cpp:693] Ignoring source layer train_data
I1108 04:59:30.837597  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0615625
I1108 04:59:30.837627  3455 solver.cpp:404]     Test net output #1: loss = 3.86457 (* 1 = 3.86457 loss)
I1108 04:59:30.975925  3455 solver.cpp:228] Iteration 88500, loss = 3.85946
I1108 04:59:30.975956  3455 solver.cpp:244]     Train net output #0: loss = 3.85946 (* 1 = 3.85946 loss)
I1108 04:59:30.975965  3455 sgd_solver.cpp:106] Iteration 88500, lr = 0
I1108 05:03:43.750663  3455 solver.cpp:337] Iteration 89000, Testing net (#0)
I1108 05:03:43.750708  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:04:11.712991  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0597656
I1108 05:04:11.713023  3455 solver.cpp:404]     Test net output #1: loss = 3.85994 (* 1 = 3.85994 loss)
I1108 05:04:11.851191  3455 solver.cpp:228] Iteration 89000, loss = 3.80849
I1108 05:04:11.851222  3455 solver.cpp:244]     Train net output #0: loss = 3.80849 (* 1 = 3.80849 loss)
I1108 05:04:11.851229  3455 sgd_solver.cpp:106] Iteration 89000, lr = 0
I1108 05:08:24.609599  3455 solver.cpp:337] Iteration 89500, Testing net (#0)
I1108 05:08:24.609657  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:08:52.582511  3455 solver.cpp:404]     Test net output #0: accuracy = 0.061875
I1108 05:08:52.582541  3455 solver.cpp:404]     Test net output #1: loss = 3.84636 (* 1 = 3.84636 loss)
I1108 05:08:52.720948  3455 solver.cpp:228] Iteration 89500, loss = 3.92469
I1108 05:08:52.720983  3455 solver.cpp:244]     Train net output #0: loss = 3.92469 (* 1 = 3.92469 loss)
I1108 05:08:52.720991  3455 sgd_solver.cpp:106] Iteration 89500, lr = 0
I1108 05:13:05.524884  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_90000.caffemodel
I1108 05:13:35.431787  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_90000.solverstate
I1108 05:13:37.734484  3455 solver.cpp:337] Iteration 90000, Testing net (#0)
I1108 05:13:37.734557  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:14:05.326841  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06
I1108 05:14:05.326874  3455 solver.cpp:404]     Test net output #1: loss = 3.85636 (* 1 = 3.85636 loss)
I1108 05:14:05.465436  3455 solver.cpp:228] Iteration 90000, loss = 3.83534
I1108 05:14:05.465466  3455 solver.cpp:244]     Train net output #0: loss = 3.83534 (* 1 = 3.83534 loss)
I1108 05:14:05.465473  3455 sgd_solver.cpp:106] Iteration 90000, lr = 0
I1108 05:18:18.191119  3455 solver.cpp:337] Iteration 90500, Testing net (#0)
I1108 05:18:18.191187  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:18:46.157721  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0586719
I1108 05:18:46.157747  3455 solver.cpp:404]     Test net output #1: loss = 3.86034 (* 1 = 3.86034 loss)
I1108 05:18:46.295912  3455 solver.cpp:228] Iteration 90500, loss = 3.8137
I1108 05:18:46.295939  3455 solver.cpp:244]     Train net output #0: loss = 3.8137 (* 1 = 3.8137 loss)
I1108 05:18:46.295945  3455 sgd_solver.cpp:106] Iteration 90500, lr = 0
I1108 05:22:58.998642  3455 solver.cpp:337] Iteration 91000, Testing net (#0)
I1108 05:22:58.998706  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:23:26.967048  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1108 05:23:26.967077  3455 solver.cpp:404]     Test net output #1: loss = 3.87042 (* 1 = 3.87042 loss)
I1108 05:23:27.105211  3455 solver.cpp:228] Iteration 91000, loss = 3.83049
I1108 05:23:27.105239  3455 solver.cpp:244]     Train net output #0: loss = 3.83049 (* 1 = 3.83049 loss)
I1108 05:23:27.105247  3455 sgd_solver.cpp:106] Iteration 91000, lr = 0
I1108 05:27:39.800635  3455 solver.cpp:337] Iteration 91500, Testing net (#0)
I1108 05:27:39.800693  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:28:07.768020  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0591406
I1108 05:28:07.768049  3455 solver.cpp:404]     Test net output #1: loss = 3.8619 (* 1 = 3.8619 loss)
I1108 05:28:07.906081  3455 solver.cpp:228] Iteration 91500, loss = 3.96772
I1108 05:28:07.906111  3455 solver.cpp:244]     Train net output #0: loss = 3.96772 (* 1 = 3.96772 loss)
I1108 05:28:07.906117  3455 sgd_solver.cpp:106] Iteration 91500, lr = 0
I1108 05:32:20.595966  3455 solver.cpp:337] Iteration 92000, Testing net (#0)
I1108 05:32:20.596026  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:32:48.572481  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0603906
I1108 05:32:48.572515  3455 solver.cpp:404]     Test net output #1: loss = 3.86628 (* 1 = 3.86628 loss)
I1108 05:32:48.710394  3455 solver.cpp:228] Iteration 92000, loss = 3.90206
I1108 05:32:48.710423  3455 solver.cpp:244]     Train net output #0: loss = 3.90206 (* 1 = 3.90206 loss)
I1108 05:32:48.710431  3455 sgd_solver.cpp:106] Iteration 92000, lr = 0
I1108 05:37:01.378209  3455 solver.cpp:337] Iteration 92500, Testing net (#0)
I1108 05:37:01.378260  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:37:29.337013  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0625
I1108 05:37:29.337040  3455 solver.cpp:404]     Test net output #1: loss = 3.86414 (* 1 = 3.86414 loss)
I1108 05:37:29.475540  3455 solver.cpp:228] Iteration 92500, loss = 3.84349
I1108 05:37:29.475569  3455 solver.cpp:244]     Train net output #0: loss = 3.84349 (* 1 = 3.84349 loss)
I1108 05:37:29.475575  3455 sgd_solver.cpp:106] Iteration 92500, lr = 0
I1108 05:41:42.186013  3455 solver.cpp:337] Iteration 93000, Testing net (#0)
I1108 05:41:42.186074  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:42:10.162366  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 05:42:10.162398  3455 solver.cpp:404]     Test net output #1: loss = 3.85511 (* 1 = 3.85511 loss)
I1108 05:42:10.300703  3455 solver.cpp:228] Iteration 93000, loss = 3.80783
I1108 05:42:10.300731  3455 solver.cpp:244]     Train net output #0: loss = 3.80783 (* 1 = 3.80783 loss)
I1108 05:42:10.300737  3455 sgd_solver.cpp:106] Iteration 93000, lr = 0
I1108 05:46:23.052971  3455 solver.cpp:337] Iteration 93500, Testing net (#0)
I1108 05:46:23.053037  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:46:51.033982  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0584375
I1108 05:46:51.034005  3455 solver.cpp:404]     Test net output #1: loss = 3.86689 (* 1 = 3.86689 loss)
I1108 05:46:51.172432  3455 solver.cpp:228] Iteration 93500, loss = 3.87398
I1108 05:46:51.172463  3455 solver.cpp:244]     Train net output #0: loss = 3.87398 (* 1 = 3.87398 loss)
I1108 05:46:51.172472  3455 sgd_solver.cpp:106] Iteration 93500, lr = 0
I1108 05:51:03.952855  3455 solver.cpp:337] Iteration 94000, Testing net (#0)
I1108 05:51:03.952913  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:51:31.912869  3455 solver.cpp:404]     Test net output #0: accuracy = 0.060625
I1108 05:51:31.912901  3455 solver.cpp:404]     Test net output #1: loss = 3.87814 (* 1 = 3.87814 loss)
I1108 05:51:32.050611  3455 solver.cpp:228] Iteration 94000, loss = 3.80374
I1108 05:51:32.050643  3455 solver.cpp:244]     Train net output #0: loss = 3.80374 (* 1 = 3.80374 loss)
I1108 05:51:32.050652  3455 sgd_solver.cpp:106] Iteration 94000, lr = 0
I1108 05:55:44.805650  3455 solver.cpp:337] Iteration 94500, Testing net (#0)
I1108 05:55:44.805696  3455 net.cpp:693] Ignoring source layer train_data
I1108 05:56:12.767146  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0607031
I1108 05:56:12.767180  3455 solver.cpp:404]     Test net output #1: loss = 3.87334 (* 1 = 3.87334 loss)
I1108 05:56:12.905560  3455 solver.cpp:228] Iteration 94500, loss = 3.83671
I1108 05:56:12.905591  3455 solver.cpp:244]     Train net output #0: loss = 3.83671 (* 1 = 3.83671 loss)
I1108 05:56:12.905598  3455 sgd_solver.cpp:106] Iteration 94500, lr = 0
I1108 06:00:25.651918  3455 solver.cpp:337] Iteration 95000, Testing net (#0)
I1108 06:00:25.651976  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:00:53.638051  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0608594
I1108 06:00:53.638080  3455 solver.cpp:404]     Test net output #1: loss = 3.85841 (* 1 = 3.85841 loss)
I1108 06:00:53.775908  3455 solver.cpp:228] Iteration 95000, loss = 3.88126
I1108 06:00:53.775940  3455 solver.cpp:244]     Train net output #0: loss = 3.88126 (* 1 = 3.88126 loss)
I1108 06:00:53.775948  3455 sgd_solver.cpp:106] Iteration 95000, lr = 0
I1108 06:05:06.512951  3455 solver.cpp:337] Iteration 95500, Testing net (#0)
I1108 06:05:06.513006  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:05:34.477540  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0615625
I1108 06:05:34.477567  3455 solver.cpp:404]     Test net output #1: loss = 3.87968 (* 1 = 3.87968 loss)
I1108 06:05:34.615713  3455 solver.cpp:228] Iteration 95500, loss = 3.91741
I1108 06:05:34.615746  3455 solver.cpp:244]     Train net output #0: loss = 3.91741 (* 1 = 3.91741 loss)
I1108 06:05:34.615753  3455 sgd_solver.cpp:106] Iteration 95500, lr = 0
I1108 06:09:47.346813  3455 solver.cpp:337] Iteration 96000, Testing net (#0)
I1108 06:09:47.346873  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:10:15.320377  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0577344
I1108 06:10:15.320410  3455 solver.cpp:404]     Test net output #1: loss = 3.85617 (* 1 = 3.85617 loss)
I1108 06:10:15.458585  3455 solver.cpp:228] Iteration 96000, loss = 3.83144
I1108 06:10:15.458613  3455 solver.cpp:244]     Train net output #0: loss = 3.83144 (* 1 = 3.83144 loss)
I1108 06:10:15.458621  3455 sgd_solver.cpp:106] Iteration 96000, lr = 0
I1108 06:14:28.183378  3455 solver.cpp:337] Iteration 96500, Testing net (#0)
I1108 06:14:28.183454  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:14:56.147285  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0604687
I1108 06:14:56.147315  3455 solver.cpp:404]     Test net output #1: loss = 3.85787 (* 1 = 3.85787 loss)
I1108 06:14:56.285751  3455 solver.cpp:228] Iteration 96500, loss = 3.76675
I1108 06:14:56.285785  3455 solver.cpp:244]     Train net output #0: loss = 3.76675 (* 1 = 3.76675 loss)
I1108 06:14:56.285792  3455 sgd_solver.cpp:106] Iteration 96500, lr = 0
I1108 06:19:08.983014  3455 solver.cpp:337] Iteration 97000, Testing net (#0)
I1108 06:19:08.983079  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:19:36.974520  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0588281
I1108 06:19:36.974550  3455 solver.cpp:404]     Test net output #1: loss = 3.86362 (* 1 = 3.86362 loss)
I1108 06:19:37.113132  3455 solver.cpp:228] Iteration 97000, loss = 3.79159
I1108 06:19:37.113162  3455 solver.cpp:244]     Train net output #0: loss = 3.79159 (* 1 = 3.79159 loss)
I1108 06:19:37.113170  3455 sgd_solver.cpp:106] Iteration 97000, lr = 0
I1108 06:23:49.857175  3455 solver.cpp:337] Iteration 97500, Testing net (#0)
I1108 06:23:49.857241  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:24:17.858259  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0616406
I1108 06:24:17.858289  3455 solver.cpp:404]     Test net output #1: loss = 3.85724 (* 1 = 3.85724 loss)
I1108 06:24:17.996166  3455 solver.cpp:228] Iteration 97500, loss = 3.84814
I1108 06:24:17.996197  3455 solver.cpp:244]     Train net output #0: loss = 3.84814 (* 1 = 3.84814 loss)
I1108 06:24:17.996206  3455 sgd_solver.cpp:106] Iteration 97500, lr = 0
I1108 06:28:30.744101  3455 solver.cpp:337] Iteration 98000, Testing net (#0)
I1108 06:28:30.744165  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:28:58.744304  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0610156
I1108 06:28:58.744333  3455 solver.cpp:404]     Test net output #1: loss = 3.88929 (* 1 = 3.88929 loss)
I1108 06:28:58.882622  3455 solver.cpp:228] Iteration 98000, loss = 3.84123
I1108 06:28:58.882652  3455 solver.cpp:244]     Train net output #0: loss = 3.84123 (* 1 = 3.84123 loss)
I1108 06:28:58.882659  3455 sgd_solver.cpp:106] Iteration 98000, lr = 0
I1108 06:33:11.632277  3455 solver.cpp:337] Iteration 98500, Testing net (#0)
I1108 06:33:11.632340  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:33:39.646903  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0614844
I1108 06:33:39.646939  3455 solver.cpp:404]     Test net output #1: loss = 3.89019 (* 1 = 3.89019 loss)
I1108 06:33:39.785053  3455 solver.cpp:228] Iteration 98500, loss = 3.79483
I1108 06:33:39.785089  3455 solver.cpp:244]     Train net output #0: loss = 3.79483 (* 1 = 3.79483 loss)
I1108 06:33:39.785099  3455 sgd_solver.cpp:106] Iteration 98500, lr = 0
I1108 06:37:52.569728  3455 solver.cpp:337] Iteration 99000, Testing net (#0)
I1108 06:37:52.569789  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:38:20.555435  3455 solver.cpp:404]     Test net output #0: accuracy = 0.06
I1108 06:38:20.555470  3455 solver.cpp:404]     Test net output #1: loss = 3.86378 (* 1 = 3.86378 loss)
I1108 06:38:20.693653  3455 solver.cpp:228] Iteration 99000, loss = 3.81718
I1108 06:38:20.693682  3455 solver.cpp:244]     Train net output #0: loss = 3.81718 (* 1 = 3.81718 loss)
I1108 06:38:20.693691  3455 sgd_solver.cpp:106] Iteration 99000, lr = 0
I1108 06:42:33.431067  3455 solver.cpp:337] Iteration 99500, Testing net (#0)
I1108 06:42:33.431139  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:43:01.429771  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0575
I1108 06:43:01.429800  3455 solver.cpp:404]     Test net output #1: loss = 3.8889 (* 1 = 3.8889 loss)
I1108 06:43:01.568029  3455 solver.cpp:228] Iteration 99500, loss = 3.85992
I1108 06:43:01.568061  3455 solver.cpp:244]     Train net output #0: loss = 3.85992 (* 1 = 3.85992 loss)
I1108 06:43:01.568069  3455 sgd_solver.cpp:106] Iteration 99500, lr = 0
I1108 06:47:14.349248  3455 solver.cpp:454] Snapshotting to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_100000.caffemodel
I1108 06:47:41.207870  3455 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mywork/hmdb51/snapshot/hmdb_vgg2048_iter_100000.solverstate
I1108 06:47:43.643801  3455 solver.cpp:317] Iteration 100000, loss = 3.80511
I1108 06:47:43.643833  3455 solver.cpp:337] Iteration 100000, Testing net (#0)
I1108 06:47:43.643839  3455 net.cpp:693] Ignoring source layer train_data
I1108 06:48:11.226554  3455 solver.cpp:404]     Test net output #0: accuracy = 0.0629688
I1108 06:48:11.226647  3455 solver.cpp:404]     Test net output #1: loss = 3.8579 (* 1 = 3.8579 loss)
I1108 06:48:11.226656  3455 solver.cpp:322] Optimization Done.
I1108 06:48:11.233011  3455 caffe.cpp:254] Optimization Done.
